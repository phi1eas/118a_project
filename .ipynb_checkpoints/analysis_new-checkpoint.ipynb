{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Questions_\n",
    "- Large and small datasets, what is better: same relative or absolute train size?\n",
    "  (or choose subset of data a priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "train_size     = 0.8  # rel\n",
    "max_train_size = 1000 # abs\n",
    "\n",
    "clf_param_dict = {'svm': {'C': [1e-7, 1e-6, 1e-5]},\n",
    "                  'knn': {'n_neighbors': np.arange(1, 31)}} # ...\n",
    "\n",
    "clf_dict       = {'svm': svm.SVC(),\n",
    "                  'knn': neighbors.KNeighborsClassifier()} # ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Methods\n",
    "\n",
    "def init_clf(clf_name, clf_dict=clf_dict):\n",
    "    return(copy.deepcopy(clf_dict[clf_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Data\n",
    "\n",
    "# Prep part yields this:\n",
    "wdbc_X, wdbc_y       # (569, 30)\n",
    "income_X, income_y   # (32.5k, 15)\n",
    "iris_X, iris_y       # (150, 4)\n",
    "covtype_X, covtype_y # (581k, 54)\n",
    "letter_X, letter_y   # (20k, 16)\n",
    "\n",
    "all_data_dict = {'wdbc':      (wdbc_X, wdbc_y),\n",
    "                 'income':    (income_X, income_y),\n",
    "                 'iris':      (iris_X, iris_y)\n",
    "                 'covtype':   (covtype_X, covtype_y),\n",
    "                 'letter':    (letter_X, letter_y)}\n",
    "\n",
    "\n",
    "# dict with train and test sets for each data set, use train_size and max_train_size\n",
    "data_dict # = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Find optimal hyperparams\n",
    "# class AutoGridSearchCV\n",
    "#  VARIABLES:\n",
    "#  \n",
    "#  clf_hyperparam_grid, cv, n_jobs, verbose, X, y, has_fit, best_params_\n",
    "#  \n",
    "#  METHODS:\n",
    "#   __init__(self, clf_hyperparam_grid, cv, n_jobs, verbose)\n",
    "#  fit(self, X, y)  # fit, find best hyperparameters\n",
    "#  predict(self, X) # call clf's fit method with best set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?GridSearchCV.fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
