{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from hyperparams import hyperparam_explorer # my package\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "RND_SEED        = 0\n",
    "CLF_DICT        = {'svm': svm.SVC(),\n",
    "                   'dt':  tree.DecisionTreeClassifier(),\n",
    "                   'rf':  ensemble.RandomForestClassifier(),\n",
    "                   'knn': neighbors.KNeighborsClassifier(),\n",
    "                   'ann': neural_network.MLPClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, ratio):\n",
    "    \"\"\"\n",
    "    Splits dataset into training and test set of specified size.\n",
    "    \n",
    "        data:  The data to be split.\n",
    "        \n",
    "        ratio: Ratio of first (training) subset.\n",
    "        \n",
    "    Returns two datasets: training and test set.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_num  = int(np.round(ratio*data.shape[0]))\n",
    "    data_train = data[:train_num]\n",
    "    data_test  = data[train_num:]\n",
    "    return(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def shuffle(df):\n",
    "    \"\"\"\n",
    "    Shuffles dataset using seed specified in RND_SEED (see config part above).\n",
    "    \n",
    "        df:  Dataset to be shuffled.\n",
    "        \n",
    "    Returns shuffled dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    return(df.sample(frac=1, random_state=np.random.RandomState(seed=RND_SEED)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load, prepare, and shuffle breast cancer data\n",
    "wdbc_X_and_y = pd.read_csv('data/wdbc.data', header = None).iloc[:, 1:] # drop ID, then first col = y\n",
    "wdbc_X_and_y = shuffle(wdbc_X_and_y)\n",
    "wdbc_y = wdbc_X_and_y.iloc[:, 0]\n",
    "wdbc_X = wdbc_X_and_y.iloc[:, 1:]\n",
    "\n",
    "# Transform y from (B, M) to (-1, 1)\n",
    "wdbc_y = wdbc_y.map({'B': -1, 'M': 1})\n",
    "\n",
    "# Split to 80% training and 20% test set\n",
    "wdbc_X_train, wdbc_X_test = split_train_test(wdbc_X, 0.8)\n",
    "wdbc_y_train, wdbc_y_test = split_train_test(wdbc_y, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load, prepare, and shuffle adult income data\n",
    "income_X_and_y = pd.read_csv('data/adult.data', header=None)\n",
    "income_X_and_y.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                         'marital-status', 'occupation', 'relationship',\n",
    "                         'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                         'native-country', 'income']\n",
    "income_X_and_y = shuffle(income_X_and_y)\n",
    "\n",
    "# one-hot encode categorical variables\n",
    "income_categorical_vars = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'native-country']\n",
    "income_X_and_y_onehot = pd.DataFrame()\n",
    "for var in income_categorical_vars:\n",
    "    dummy_coded_var_df = pd.get_dummies(income_X_and_y[var], prefix=var)\n",
    "    income_X_and_y_onehot = pd.concat([income_X_and_y_onehot, dummy_coded_var_df], axis=1)\n",
    "\n",
    "# add remaining columns to one-hot encoded df\n",
    "income_X_and_y = pd.concat([income_X_and_y_onehot,\n",
    "                            income_X_and_y.loc[:, income_X_and_y.columns[\n",
    "                                np.logical_not(np.in1d(income_X_and_y.columns, income_categorical_vars))]]],\n",
    "                           axis=1)\n",
    "\n",
    "income_y = income_X_and_y.loc[:, 'income']\n",
    "income_X = income_X_and_y.drop('income', axis=1)\n",
    "\n",
    "# Transform y from (<=50K, >50K) to (-1, 1)\n",
    "income_y = income_y.map({' <=50K': -1, ' >50K': 1})\n",
    "\n",
    "# Split to 80% training and 20% test set\n",
    "income_X_train, income_X_test = split_train_test(income_X, 0.8)\n",
    "income_y_train, income_y_test = split_train_test(income_y, 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparam study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict       = {'wdbc':   [wdbc_X_train, wdbc_y_train],\n",
    "                   'income': [income_X_train, income_y_train]}\n",
    "hyperparam_dict = {'knn': {'n_neighbors': np.arange(1, 51)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on part 1 of 100...\n",
      "Working on part 2 of 100...\n",
      "Working on part 3 of 100...\n",
      "Working on part 4 of 100...\n",
      "Working on part 5 of 100...\n",
      "Working on part 6 of 100...\n",
      "Working on part 7 of 100...\n",
      "Working on part 8 of 100...\n",
      "Working on part 9 of 100...\n",
      "Working on part 10 of 100...\n",
      "Working on part 11 of 100...\n",
      "Working on part 12 of 100...\n",
      "Working on part 13 of 100...\n",
      "Working on part 14 of 100...\n",
      "Working on part 15 of 100...\n",
      "Working on part 16 of 100...\n",
      "Working on part 17 of 100...\n",
      "Working on part 18 of 100...\n",
      "Working on part 19 of 100...\n",
      "Working on part 20 of 100...\n",
      "Working on part 21 of 100...\n",
      "Working on part 22 of 100...\n",
      "Working on part 23 of 100...\n",
      "Working on part 24 of 100...\n",
      "Working on part 25 of 100...\n",
      "Working on part 26 of 100...\n",
      "Working on part 27 of 100...\n",
      "Working on part 28 of 100...\n",
      "Working on part 29 of 100...\n",
      "Working on part 30 of 100...\n",
      "Working on part 31 of 100...\n",
      "Working on part 32 of 100...\n",
      "Working on part 33 of 100...\n",
      "Working on part 34 of 100...\n",
      "Working on part 35 of 100...\n",
      "Working on part 36 of 100...\n",
      "Working on part 37 of 100...\n",
      "Working on part 38 of 100...\n",
      "Working on part 39 of 100...\n",
      "Working on part 40 of 100...\n",
      "Working on part 41 of 100...\n",
      "Working on part 42 of 100...\n",
      "Working on part 43 of 100...\n",
      "Working on part 44 of 100...\n",
      "Working on part 45 of 100...\n",
      "Working on part 46 of 100...\n",
      "Working on part 47 of 100...\n",
      "Working on part 48 of 100...\n",
      "Working on part 49 of 100...\n",
      "Working on part 50 of 100...\n",
      "Working on part 51 of 100...\n",
      "Working on part 52 of 100...\n",
      "Working on part 53 of 100...\n",
      "Working on part 54 of 100...\n",
      "Working on part 55 of 100...\n",
      "Working on part 56 of 100...\n",
      "Working on part 57 of 100...\n",
      "Working on part 58 of 100...\n",
      "Working on part 59 of 100...\n",
      "Working on part 60 of 100...\n",
      "Working on part 61 of 100...\n",
      "Working on part 62 of 100...\n",
      "Working on part 63 of 100...\n",
      "Working on part 64 of 100...\n",
      "Working on part 65 of 100...\n",
      "Working on part 66 of 100...\n",
      "Working on part 67 of 100...\n",
      "Working on part 68 of 100...\n",
      "Working on part 69 of 100...\n",
      "Working on part 70 of 100...\n",
      "Working on part 71 of 100...\n",
      "Working on part 72 of 100...\n",
      "Working on part 73 of 100...\n",
      "Working on part 74 of 100...\n",
      "Working on part 75 of 100...\n",
      "Working on part 76 of 100...\n",
      "Working on part 77 of 100...\n",
      "Working on part 78 of 100...\n",
      "Working on part 79 of 100...\n",
      "Working on part 80 of 100...\n",
      "Working on part 81 of 100...\n",
      "Working on part 82 of 100...\n",
      "Working on part 83 of 100...\n",
      "Working on part 84 of 100...\n",
      "Working on part 85 of 100...\n",
      "Working on part 86 of 100...\n",
      "Working on part 87 of 100...\n",
      "Working on part 88 of 100...\n",
      "Working on part 89 of 100...\n",
      "Working on part 90 of 100...\n",
      "Working on part 91 of 100...\n",
      "Working on part 92 of 100...\n",
      "Working on part 93 of 100...\n",
      "Working on part 94 of 100...\n",
      "Working on part 95 of 100...\n",
      "Working on part 96 of 100...\n",
      "Working on part 97 of 100...\n",
      "Working on part 98 of 100...\n",
      "Working on part 99 of 100...\n",
      "Working on part 100 of 100...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'income': {'knn':     n_neighbors  scores_mean  scores_sd\n",
       "  0           1.0     0.723828   0.004849\n",
       "  1           2.0     0.782218   0.002868\n",
       "  2           3.0     0.752236   0.002545\n",
       "  3           4.0     0.783792   0.003735\n",
       "  4           5.0     0.772659   0.004268\n",
       "  5           6.0     0.788744   0.003078\n",
       "  6           7.0     0.780567   0.004144\n",
       "  7           8.0     0.791431   0.003210\n",
       "  8           9.0     0.786249   0.003340\n",
       "  9          10.0     0.794387   0.001353\n",
       "  10         11.0     0.790779   0.002665\n",
       "  11         12.0     0.794426   0.002463\n",
       "  12         13.0     0.793812   0.002208\n",
       "  13         14.0     0.796038   0.001513\n",
       "  14         15.0     0.795117   0.002223\n",
       "  15         16.0     0.797689   0.001792\n",
       "  16         17.0     0.796998   0.002379\n",
       "  17         18.0     0.796883   0.002610\n",
       "  18         19.0     0.797228   0.002764\n",
       "  19         20.0     0.797152   0.002643\n",
       "  20         21.0     0.797497   0.002954\n",
       "  21         22.0     0.796537   0.002604\n",
       "  22         23.0     0.797420   0.002489\n",
       "  23         24.0     0.797190   0.002613\n",
       "  24         25.0     0.797612   0.001914\n",
       "  25         26.0     0.796806   0.002206\n",
       "  26         27.0     0.797420   0.002349\n",
       "  27         28.0     0.796422   0.001871\n",
       "  28         29.0     0.796729   0.002009\n",
       "  29         30.0     0.796192   0.002248\n",
       "  30         31.0     0.796077   0.002530\n",
       "  31         32.0     0.795770   0.002359\n",
       "  32         33.0     0.796384   0.002688\n",
       "  33         34.0     0.795770   0.002342\n",
       "  34         35.0     0.795462   0.002484\n",
       "  35         36.0     0.794503   0.002369\n",
       "  36         37.0     0.794695   0.002321\n",
       "  37         38.0     0.794157   0.001876\n",
       "  38         39.0     0.794618   0.002197\n",
       "  39         40.0     0.793888   0.002289\n",
       "  40         41.0     0.794234   0.002246\n",
       "  41         42.0     0.793581   0.002191\n",
       "  42         43.0     0.793696   0.002542\n",
       "  43         44.0     0.793313   0.002660\n",
       "  44         45.0     0.793466   0.002530\n",
       "  45         46.0     0.792737   0.002513\n",
       "  46         47.0     0.793082   0.002548\n",
       "  47         48.0     0.792468   0.002221\n",
       "  48         49.0     0.792814   0.002230\n",
       "  49         50.0     0.792161   0.001946},\n",
       " 'wdbc': {'knn':     n_neighbors  scores_mean  scores_sd\n",
       "  0           1.0     0.918601   0.029216\n",
       "  1           2.0     0.925147   0.027391\n",
       "  2           3.0     0.918529   0.020855\n",
       "  3           4.0     0.922901   0.028245\n",
       "  4           5.0     0.929520   0.029360\n",
       "  5           6.0     0.931693   0.030942\n",
       "  6           7.0     0.931693   0.030063\n",
       "  7           8.0     0.929471   0.033437\n",
       "  8           9.0     0.931645   0.036080\n",
       "  9          10.0     0.931645   0.036080\n",
       "  10         11.0     0.931645   0.036080\n",
       "  11         12.0     0.929423   0.035562\n",
       "  12         13.0     0.929423   0.035562\n",
       "  13         14.0     0.927249   0.032730\n",
       "  14         15.0     0.927249   0.032730\n",
       "  15         16.0     0.927273   0.027950\n",
       "  16         17.0     0.927273   0.027950\n",
       "  17         18.0     0.922828   0.030895\n",
       "  18         19.0     0.925051   0.031170\n",
       "  19         20.0     0.925051   0.031170\n",
       "  20         21.0     0.922877   0.029217\n",
       "  21         22.0     0.922828   0.030895\n",
       "  22         23.0     0.920655   0.028756\n",
       "  23         24.0     0.922828   0.030895\n",
       "  24         25.0     0.922828   0.030895\n",
       "  25         26.0     0.918432   0.028978\n",
       "  26         27.0     0.918432   0.028978\n",
       "  27         28.0     0.916258   0.026325\n",
       "  28         29.0     0.916258   0.026325\n",
       "  29         30.0     0.914085   0.024168\n",
       "  30         31.0     0.918456   0.025411\n",
       "  31         32.0     0.916258   0.026325\n",
       "  32         33.0     0.920630   0.027979\n",
       "  33         34.0     0.918408   0.031513\n",
       "  34         35.0     0.920630   0.027979\n",
       "  35         36.0     0.922852   0.024741\n",
       "  36         37.0     0.918456   0.026324\n",
       "  37         38.0     0.920654   0.026159\n",
       "  38         39.0     0.916258   0.029024\n",
       "  39         40.0     0.916282   0.025316\n",
       "  40         41.0     0.911862   0.029321\n",
       "  41         42.0     0.911911   0.022650\n",
       "  42         43.0     0.916258   0.029699\n",
       "  43         44.0     0.914085   0.026051\n",
       "  44         45.0     0.916258   0.029699\n",
       "  45         46.0     0.914085   0.029456\n",
       "  46         47.0     0.914085   0.029456\n",
       "  47         48.0     0.914085   0.029456\n",
       "  48         49.0     0.911862   0.032385\n",
       "  49         50.0     0.914085   0.029456}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_exp1 = hyperparam_explorer(data_dict, hyperparam_dict, CLF_DICT, cv=5)\n",
    "hp_exp1.work()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hp_exp1.save('wdbc_income_knn_k_1_50')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
