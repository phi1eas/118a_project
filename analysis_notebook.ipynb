{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This notebook requires additional resources (such as data) to run. If you want to run this notebook, please pull a complete dump from GitHub: https://github.com/phi1eas/118a_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import string\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "MAX_DATA_SIZE  = 2000\n",
    "RND_SEED       = 1\n",
    "FIGSIZE        = (8, 6)\n",
    "CLF_DICT       = {'logreg': linear_model.LogisticRegression(),\n",
    "                  'knn':    neighbors.KNeighborsClassifier(),\n",
    "                  'rf':     ensemble.RandomForestClassifier(),\n",
    "                  'svm':    svm.SVC(),\n",
    "                  'dt':     tree.DecisionTreeClassifier(),\n",
    "                  'bagdt':  ensemble.BaggingClassifier(),\n",
    "                  'bstdt':  ensemble.AdaBoostClassifier()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Methods and classes\n",
    "\n",
    "def size_info(data_dict):\n",
    "    ### Size info\n",
    "    print(\"Data sizes:\")\n",
    "    for data_name, data_tuple in data_dict.items():\n",
    "        print(\"\\n{}:\\nX: {}\\ny: {}\".format(data_name, data_tuple[0].shape, data_tuple[1].shape))\n",
    "\n",
    "def shuffle_data(data_dict, seed):\n",
    "    shuffled_data_dict = dict()\n",
    "    for data_name, data_tuple in data_dict.items():\n",
    "        X = data_tuple[0]\n",
    "        y = data_tuple[1]\n",
    "        \n",
    "        X_and_y = pd.concat([X, y], axis=1)\n",
    "\n",
    "        X_and_y_shuffled = X_and_y.sample(frac=1, random_state=np.random.RandomState(seed=seed))\n",
    "        \n",
    "        X_shuffled = X_and_y_shuffled.iloc[:, :-1]\n",
    "        y_shuffled = X_and_y_shuffled.iloc[:, -1]\n",
    "    \n",
    "        shuffled_data_dict[data_name] = (X_shuffled, y_shuffled)\n",
    "    \n",
    "    return(shuffled_data_dict)\n",
    "\n",
    "def train_test_split_data(all_data_dict, train_size, shuffle=True, random_seed=None):\n",
    "    \"\"\"\n",
    "    Output example for shuffled_data_dict = {'wdbc': (wdbc_X, wdbc_y)}:\n",
    "    out = ({'wdbc': (wdbc_X_train, wdbc_y_train)}, {'wdbc': (wdbc_X_test, wdbc_y_test)})\n",
    "    \"\"\"\n",
    "    \n",
    "    train_data_dict = dict()\n",
    "    test_data_dict  = dict()\n",
    "    for data_name, data_X_y_tuple in all_data_dict.items():\n",
    "        X = data_X_y_tuple[0]\n",
    "        y = data_X_y_tuple[1]\n",
    "        \n",
    "        X_tr, X_te, y_tr, y_te = model_selection.train_test_split(\n",
    "            X, y,\n",
    "            train_size=train_size,\n",
    "            random_state=np.random.RandomState(seed=random_seed),\n",
    "            shuffle=shuffle)\n",
    "        train_data_dict[data_name] = (X_tr, y_tr)\n",
    "        test_data_dict[data_name]  = (X_te, y_te)\n",
    "        \n",
    "    return(train_data_dict, test_data_dict)\n",
    "\n",
    "def avg_sd_across_shuffles(shuffles_scores_list):\n",
    "    n_shuffles = len(shuffles_scores_list)\n",
    "\n",
    "    shuffles_avg_scores = dict()\n",
    "    shuffles_sd_scores  = dict()\n",
    "    for data_name in shuffles_scores_list[0].keys():\n",
    "        shuffles_avg_scores[data_name] = dict()\n",
    "        shuffles_sd_scores[data_name]  = dict()\n",
    "        for clf_name in shuffles_scores_list[0][data_name].keys():\n",
    "            shuffles_scores = list()\n",
    "            for shuffle_i in np.arange(n_shuffles):\n",
    "                shuffles_scores.append(shuffles_scores_list[shuffle_i][data_name][clf_name])\n",
    "\n",
    "            scores_mean = np.mean(shuffles_scores)\n",
    "            scores_sd   = np.std(shuffles_scores)\n",
    "\n",
    "            shuffles_avg_scores[data_name][clf_name] = scores_mean\n",
    "            shuffles_sd_scores[data_name][clf_name]  = scores_sd\n",
    "            \n",
    "    return(shuffles_avg_scores, shuffles_sd_scores)\n",
    "\n",
    "def avg_clf_scores_across_data(splits_shuffles_avg_scores_dict):\n",
    "    \"\"\"\n",
    "    Mean across data\n",
    "      out: {0.2: {'knn': 0.9}}\n",
    "      for splits_shuffles_avg_train_scores_dict and splits_shuffles_avg_test_scores_dict\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_scores_clf_dict = dict()\n",
    "\n",
    "    for train_split, data_dict in splits_shuffles_avg_scores_dict.items():\n",
    "        across_data_scores_clf_dict = dict()\n",
    "\n",
    "        # Restructure data such that we have lists of data_scores for each clf\n",
    "        for data_name, clf_dict in data_dict.items():\n",
    "            for clf_name, score in clf_dict.items():\n",
    "                if clf_name not in across_data_scores_clf_dict:\n",
    "                    across_data_scores_clf_dict[clf_name] = [score]\n",
    "                else:\n",
    "                    across_data_scores_clf_dict[clf_name].append(score)\n",
    "\n",
    "        # Now average across data for each clf\n",
    "        across_data_avg_score_clf_dict = dict()\n",
    "        for clf_name, across_data_scores in across_data_scores_clf_dict.items():\n",
    "            across_data_avg_score_clf_dict[clf_name] = np.mean(across_data_scores_clf_dict[clf_name])\n",
    "\n",
    "        avg_scores_clf_dict[train_split] = across_data_avg_score_clf_dict\n",
    "    return(avg_scores_clf_dict)\n",
    "\n",
    "\n",
    "def init_clf(clf_name, clf_dict=CLF_DICT):\n",
    "    return(copy.deepcopy(clf_dict[clf_name]))\n",
    "\n",
    "class BigLoop:\n",
    "    data_dict = None\n",
    "    train_splits = None\n",
    "    n_shuffles = None\n",
    "    cv = None\n",
    "    clf_param_dict = None\n",
    "    method = None\n",
    "    n_jobs = None\n",
    "    verbose = None\n",
    "    knn_fillup = None\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    splits_shuffles_train_scores_dict = None\n",
    "    splits_shuffles_test_scores_dict  = None\n",
    "    magicml_dict                      = None\n",
    "    \n",
    "    def __init__(self, data_dict, clf_param_dict, train_splits, n_shuffles, cv, knn_fillup=None, method='grid_search', n_iter=None, n_jobs=None, verbose=False):\n",
    "        self.data_dict = data_dict\n",
    "        self.clf_param_dict = clf_param_dict\n",
    "        self.train_splits = train_splits\n",
    "        self.n_shuffles = n_shuffles\n",
    "        self.cv = cv\n",
    "        self.method = method\n",
    "        self.n_iter = n_iter\n",
    "        self.n_jobs = n_jobs\n",
    "        self.verbose = verbose\n",
    "        self.knn_fillup = knn_fillup\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def plot_avg_scores_by_hyperparam_data_clf(self, clf_name, x_param_name, plot_train_split, style_list=['ro-', 'gx-', 'b.-', 'y<-', 'c>-']):\n",
    "        \n",
    "        # Create one df with all entries, indicating shuffle index as well\n",
    "        plot_df = pd.DataFrame()\n",
    "        for shuffle_idx, magic_ml_shuffle in enumerate(self.magicml_dict[plot_train_split]):\n",
    "            add_df = magic_ml_shuffle.scores_df[clf_name]\n",
    "            add_df['shuffle_idx'] = shuffle_idx\n",
    "            plot_df = pd.concat((plot_df, add_df))\n",
    "\n",
    "        plot_df = plot_df.groupby([x_param_name, 'data_name']).mean().reset_index()\n",
    "        plot_df = plot_df.drop('shuffle_idx', axis=1)\n",
    "        \n",
    "        data_names = plot_df['data_name'].unique()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "        for data_idx, data_name in enumerate(data_names):\n",
    "            ax.plot(plot_df.loc[plot_df['data_name'] == data_name, x_param_name],\n",
    "                     plot_df.loc[plot_df['data_name'] == data_name, 'scores_mean'],\n",
    "                     style_list[data_idx],\n",
    "                     label=data_name)\n",
    "\n",
    "        ax.legend()\n",
    "        return(ax)\n",
    "    \n",
    "        \n",
    "    def run(self):\n",
    "        self.splits_shuffles_train_scores_dict = dict()\n",
    "        self.splits_shuffles_test_scores_dict  = dict()\n",
    "        \n",
    "        self.magicml_dict = dict()\n",
    "        \n",
    "        loop_iter  = 0\n",
    "        loop_iters = len(TRAIN_SPLITS)*N_SHUFFLES\n",
    "        for train_split in self.train_splits:\n",
    "            self.magicml_dict[train_split] = list()\n",
    "            \n",
    "            shuffles_train_scores = list() # [{'wdbc': {'knn': (tr_acc)}} for each rnd_shuffle]\n",
    "            shuffles_test_scores = list()  # [{'wdbc': {'knn': (te_acc)}} for each rnd_shuffle]\n",
    "            for shuffle_i in np.arange(self.n_shuffles):\n",
    "                loop_iter = loop_iter + 1\n",
    "                print(\"\\n-----------------\")\n",
    "                print(\"Loop iter {}/{}\".format(loop_iter, loop_iters))\n",
    "\n",
    "                shuffled_data_dict_i = shuffle_data(self.data_dict, seed=None)\n",
    "                train_data_dict, test_data_dict = train_test_split_data(shuffled_data_dict_i,\n",
    "                                                                        train_split,\n",
    "                                                                        shuffle=True,\n",
    "                                                                        random_seed=None)\n",
    "                \n",
    "                rnd_split_magic = Magic_ML(copy.deepcopy(self.clf_param_dict),\n",
    "                                           knn_fillup=self.knn_fillup,\n",
    "                                           cv=self.cv,\n",
    "                                           n_jobs=self.n_jobs,\n",
    "                                           verbose=self.verbose,\n",
    "                                           method=self.method)\n",
    "                \n",
    "                rnd_split_magic.fit(train_data_dict, n_iter=self.n_iter)\n",
    "                \n",
    "                self.magicml_dict[train_split].append(rnd_split_magic)\n",
    "\n",
    "                rnd_split_train_scores = rnd_split_magic.score(train_data_dict) # {'wdbc': {'knn': 0.8}}\n",
    "                rnd_split_test_scores  = rnd_split_magic.score(test_data_dict)  # {'wdbc': {'knn': 0.8}}\n",
    "\n",
    "                shuffles_train_scores.append(rnd_split_train_scores)\n",
    "                shuffles_test_scores.append(rnd_split_test_scores)\n",
    "\n",
    "            self.splits_shuffles_train_scores_dict[train_split] = shuffles_train_scores\n",
    "            self.splits_shuffles_test_scores_dict[train_split]  = shuffles_test_scores\n",
    "\n",
    "class Magic_ML:\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds hyperparams for set of datasets and set of classifiers with specified hyperparam grids\n",
    "    \"\"\"\n",
    "    \n",
    "    clf_param_dict  = None\n",
    "    cv              = None\n",
    "    n_jobs          = None\n",
    "    verbose         = None\n",
    "    method          = None\n",
    "    knn_fillup      = None\n",
    "    \n",
    "    # fit\n",
    "    train_data_dict       = None\n",
    "    \n",
    "    # Randomized Search\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    searcher_obj_dict = None\n",
    "    best_params_dict  = None\n",
    "    scores_df         = None # Used for plotting\n",
    "    \n",
    "    # States\n",
    "    is_fit            = False\n",
    "    \n",
    "    def __init__(self, clf_param_dict, knn_fillup=None, cv=5, n_jobs=4, verbose=False, method='grid_search'):\n",
    "        self.clf_param_dict = clf_param_dict\n",
    "        self.cv             = cv\n",
    "        self.n_jobs         = n_jobs\n",
    "        self.verbose        = verbose\n",
    "        self.method         = method\n",
    "        self.knn_fillup     = knn_fillup\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        if not self.is_fit:\n",
    "            raise Exception('You probably want to fit before you save!')\n",
    "            \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    def get_plot_by_clf(self, clf_name, x_param_name, figsize=FIGSIZE):\n",
    "        clf_scores_df = self.scores_df[clf_name]\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        sns_plot = sns.pointplot(x_param_name, 'scores_mean', data=clf_scores_df, hue='data_name', markers='.')\n",
    "        return(sns_plot)\n",
    "    \n",
    "    def create_scores_df(self):\n",
    "        # Prepare score df dict\n",
    "        clf_scores_df_dict = dict()\n",
    "        for clf_name, param_dict in self.clf_param_dict.items():\n",
    "            columns = ['data_name']\n",
    "            columns.extend(list(self.clf_param_dict[clf_name].keys()))\n",
    "            columns.extend(['scores_mean', 'scores_sd'])\n",
    "\n",
    "            clf_scores_df_dict[clf_name] = pd.DataFrame(columns=columns)\n",
    "\n",
    "        for data_name, clf_searcher_obj_dict in self.searcher_obj_dict.items():\n",
    "            for clf_name, searcher_obj in clf_searcher_obj_dict.items():\n",
    "                grid_scores = searcher_obj.skl_search_obj.grid_scores_\n",
    "\n",
    "                for grid_score in grid_scores:\n",
    "                    param_comb_dict = grid_score[0]\n",
    "                    scores_mean = np.mean(grid_score[2])\n",
    "                    scores_sd = np.std(grid_score[2])\n",
    "\n",
    "                    row = {'data_name': data_name,\n",
    "                           'scores_mean': scores_mean,\n",
    "                           'scores_sd': scores_sd}\n",
    "\n",
    "                    for param_name, param_val in param_comb_dict.items():\n",
    "                        row[param_name] = param_val\n",
    "\n",
    "                    clf_scores_df_dict[clf_name] = clf_scores_df_dict[clf_name].append(row, ignore_index = True)\n",
    "        self.scores_df = clf_scores_df_dict\n",
    "    \n",
    "    def score(self, data_dict):\n",
    "        \"\"\"\n",
    "        Output example for {'wdbc': {wdbc_X_te, wdbc_y_te)}:\n",
    "        out = {'wdbc': {'knn': 0.8}}\n",
    "\n",
    "        data_dict abstracts over X, y\n",
    "        Returns best clf's score for each combination of dataset and clf\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.is_fit:\n",
    "            raise Exception('You need to fit me first!')\n",
    "\n",
    "        score_dict = dict()\n",
    "        for data_name, data_X_y_tuple in data_dict.items():\n",
    "            X = data_X_y_tuple[0]\n",
    "            y = data_X_y_tuple[1]\n",
    "\n",
    "            score_dict[data_name] = dict()\n",
    "            for clf_name, clf_searcher_obj in self.searcher_obj_dict[data_name].items():\n",
    "                skl_search_obj = clf_searcher_obj.skl_search_obj\n",
    "                \n",
    "                score = skl_search_obj.score(X, y)\n",
    "                score_dict[data_name][clf_name] = score\n",
    "                \n",
    "        return(score_dict)\n",
    "\n",
    "    def fit(self, train_data_dict, n_iter=None):\n",
    "        self.train_data_dict = train_data_dict\n",
    "\n",
    "        if self.method == 'randomized_search' and n_iter is None:\n",
    "            raise Exception('You need to specify n_iter for randomized search')\n",
    "        self.n_iter = n_iter\n",
    "\n",
    "        searcher_obj_dict = dict()\n",
    "        best_params_dict = dict()\n",
    "        for data_name, data_tuple in self.train_data_dict.items():\n",
    "            print(\"Fitting training dataset: {} ...\".format(data_name))\n",
    "\n",
    "            X = data_tuple[0]\n",
    "            y = data_tuple[1]\n",
    "\n",
    "            searcher_obj_dict[data_name] = dict()\n",
    "            best_params_dict[data_name] = dict()\n",
    "            for clf_name, param_dict in self.clf_param_dict.items():\n",
    "                print(\"  Doing {} magic ...\".format(clf_name))\n",
    "                searcher_obj = ParamSearcher(X, y,\n",
    "                                             clf_name,\n",
    "                                             copy.deepcopy(param_dict),\n",
    "                                             self.method,\n",
    "                                             self.knn_fillup,\n",
    "                                             self.n_jobs,\n",
    "                                             self.cv,\n",
    "                                             self.verbose)\n",
    "                searcher_obj.search(self.n_iter)\n",
    "                searcher_obj_dict[data_name][clf_name] = searcher_obj\n",
    "\n",
    "                best_params_dict[data_name][clf_name] = searcher_obj.best_params_\n",
    "        self.searcher_obj_dict = searcher_obj_dict\n",
    "        self.best_params_dict = best_params_dict\n",
    "\n",
    "        self.create_scores_df()\n",
    "        self.is_fit = True\n",
    "\n",
    "class ParamSearcher:\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds hyperparams for one dataset and one classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    clf_name = None\n",
    "    param_dict = None\n",
    "    method = None\n",
    "    verbose = None\n",
    "    n_jobs = None\n",
    "    cv = None\n",
    "    knn_fillup = None\n",
    "    \n",
    "    # Randomized Search\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    skl_search_obj = None\n",
    "    best_params_ = None\n",
    "    \n",
    "    def __init__(self, X, y, clf_name, param_dict, method='grid_search', knn_fillup=None, n_jobs=4, cv=5, verbose=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.clf_name = clf_name\n",
    "        self.param_dict = param_dict\n",
    "        self.method = method\n",
    "        self.n_jobs = n_jobs\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        self.knn_fillup = knn_fillup\n",
    "        \n",
    "    def check_params(self):\n",
    "        # knn n_neighbors fillup\n",
    "        if self.clf_name == 'knn':\n",
    "            if isinstance(self.knn_fillup, int):\n",
    "                if 'n_neighbors' in self.param_dict:\n",
    "                    max_n_neighbors = int(np.floor(self.X.shape[0]/self.cv)-1)\n",
    "                    highest_n       = np.max(self.param_dict['n_neighbors'])\n",
    "                    \n",
    "                    if self.X.shape[0] > highest_n:\n",
    "                        fill_range = np.unique(np.linspace(highest_n, max_n_neighbors-1, self.knn_fillup, dtype=int))\n",
    "                        if len(fill_range) > 0:\n",
    "                            self.param_dict['n_neighbors'] = np.concatenate((self.param_dict['n_neighbors'], fill_range))\n",
    "        \n",
    "        # Check for exceeded hard limits of some params\n",
    "        if self.clf_name == 'knn':\n",
    "            if 'n_neighbors' in self.param_dict:\n",
    "                max_n_neighbors = int(np.floor(self.X.shape[0]/self.cv)-1)\n",
    "                if np.any(self.param_dict['n_neighbors'] > max_n_neighbors):\n",
    "                    print('ParamSearcher: knn: some n_neighbors > n_samples/cv-1. Restricting range to n_samples/cv-1.')\n",
    "                    self.param_dict['n_neighbors'][self.param_dict['n_neighbors'] > max_n_neighbors] = max_n_neighbors\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['n_neighbors'] = np.unique(self.param_dict['n_neighbors'])\n",
    "        elif self.clf_name == 'rf':\n",
    "            if 'max_features' in self.param_dict:\n",
    "                if np.any(self.param_dict['max_features'] > self.X.shape[1]):\n",
    "                    print('ParamSearcher: rf: some max_features > n_features. Restricting range to max_features.')\n",
    "                    self.param_dict['max_features'][self.param_dict['max_features'] > self.X.shape[1]] = self.X.shape[1]\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['max_features'] = np.unique(self.param_dict['max_features'])\n",
    "        elif self.clf_name == 'dt':\n",
    "            if 'max_features' in self.param_dict:\n",
    "                if np.any(self.param_dict['max_features'] > self.X.shape[1]):\n",
    "                    print('ParamSearcher: dt: some max_features > n_features. Restricting range to max_features.')\n",
    "                    self.param_dict['max_features'][self.param_dict['max_features'] > self.X.shape[1]] = self.X.shape[1]\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['max_features'] = np.unique(self.param_dict['max_features'])\n",
    "                    \n",
    "                    \n",
    "    def search(self, n_iter=None):\n",
    "        self.check_params()\n",
    "        \n",
    "        if self.method == 'grid_search':\n",
    "            skl_search_obj = GridSearchCV(estimator  = init_clf(self.clf_name),\n",
    "                                          param_grid = self.param_dict,\n",
    "                                          n_jobs     = self.n_jobs,\n",
    "                                          cv         = self.cv,\n",
    "                                          verbose    = self.verbose)\n",
    "        elif self.method == 'randomized_search':\n",
    "            if n_iter is None:\n",
    "                raise Exception('You need to specify n_iter for randomized search')\n",
    "            self.n_iter = n_iter\n",
    "            \n",
    "            skl_search_obj = RandomizedSearchCV(estimator           = init_clf(self.clf_name),\n",
    "                                                 param_distributions = self.param_dict,\n",
    "                                                 n_iter              = n_iter,\n",
    "                                                 n_jobs              = self.n_jobs,\n",
    "                                                 cv                  = self.cv,\n",
    "                                                 verbose             = self.verbose)\n",
    "        skl_search_obj.fit(self.X, self.y)\n",
    "        self.skl_search_obj = skl_search_obj\n",
    "        self.best_params_ = skl_search_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Temp methods\n",
    "# Only needed for old bigloop objects. These methods should be included in the class after re-run\n",
    "def plot_avg_scores_by_hyperparam_data_clf(bigloop, clf_name, x_param_name, plot_train_split, style_list=['ro-', 'gx-', 'b.-', 'y<-', 'c>-']):\n",
    "    # Create one df with all entries, indicating shuffle index as well\n",
    "    plot_df = pd.DataFrame()\n",
    "    for shuffle_idx, magic_ml_shuffle in enumerate(bigloop.magicml_dict[plot_train_split]):\n",
    "        add_df = magic_ml_shuffle.scores_df[clf_name]\n",
    "        add_df['shuffle_idx'] = shuffle_idx\n",
    "        plot_df = pd.concat((plot_df, add_df))\n",
    "\n",
    "    plot_df = plot_df.groupby([x_param_name, 'data_name']).mean().reset_index()\n",
    "    plot_df = plot_df.drop('shuffle_idx', axis=1)\n",
    "\n",
    "    data_names = plot_df['data_name'].unique()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "    for data_idx, data_name in enumerate(data_names):\n",
    "        ax.plot(plot_df.loc[plot_df['data_name'] == data_name, x_param_name],\n",
    "                 plot_df.loc[plot_df['data_name'] == data_name, 'scores_mean'],\n",
    "                 style_list[data_idx],\n",
    "                 label=data_name)\n",
    "\n",
    "    ax.legend()\n",
    "    return(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load data\n",
    "## iris\n",
    "iris_X = pd.DataFrame(datasets.load_iris()['data'])\n",
    "iris_y = pd.Series(datasets.load_iris()['target'])\n",
    "\n",
    "\n",
    "## wdbc\n",
    "wdbc_X_and_y = pd.read_csv('data/wdbc.data', header = None).iloc[:, 1:] # drop ID, then first col = y\n",
    "wdbc_y = wdbc_X_and_y.iloc[:, 0]\n",
    "wdbc_X = wdbc_X_and_y.iloc[:, 1:]\n",
    "\n",
    "wdbc_y = wdbc_y.map({'B': -1, 'M': 1}) # Transform y from (B, M) to (-1, 1)\n",
    "\n",
    "\n",
    "## income\n",
    "# Load, prepare, and shuffle adult income data\n",
    "income_X_and_y = pd.read_csv('data/adult.data', header=None)\n",
    "income_X_and_y.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                         'marital-status', 'occupation', 'relationship',\n",
    "                         'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                         'native-country', 'income']\n",
    "\n",
    "# one-hot encode categorical variables\n",
    "income_categorical_vars = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'native-country']\n",
    "income_X_and_y_onehot = pd.DataFrame()\n",
    "for var in income_categorical_vars:\n",
    "    dummy_coded_var_df = pd.get_dummies(income_X_and_y[var], prefix=var)\n",
    "    income_X_and_y_onehot = pd.concat([income_X_and_y_onehot, dummy_coded_var_df], axis=1)\n",
    "\n",
    "# add remaining columns to one-hot encoded df\n",
    "income_X_and_y = pd.concat([income_X_and_y_onehot,\n",
    "                            income_X_and_y.loc[:, income_X_and_y.columns[\n",
    "                                np.logical_not(np.in1d(income_X_and_y.columns, income_categorical_vars))]]],\n",
    "                           axis=1)\n",
    "\n",
    "income_y = income_X_and_y.loc[:, 'income']\n",
    "income_X = income_X_and_y.drop('income', axis=1)\n",
    "\n",
    "# Transform y from (<=50K, >50K) to (-1, 1)\n",
    "income_y = income_y.map({' <=50K': -1, ' >50K': 1})\n",
    "\n",
    "\n",
    "## Letter\n",
    "letter_X_and_y = pd.read_csv('data/letter.data', header=None)\n",
    "letter_X = letter_X_and_y.iloc[:, 1:]\n",
    "letter_y = letter_X_and_y.iloc[:, 0]\n",
    "\n",
    "# Transform y from A:M -> -1 and N:Z -> 1\n",
    "def alph_to_cat(letter):\n",
    "    if str.upper(letter) in list(string.ascii_uppercase[:13]):\n",
    "        return(1)\n",
    "    elif str.upper(letter) in list(string.ascii_uppercase[13:]):\n",
    "        return(-1)\n",
    "    \n",
    "letter_y = letter_y.map(alph_to_cat)\n",
    "\n",
    "## covtype\n",
    "covtype_X_and_y = pd.read_csv('data/covtype.data')\n",
    "covtype_X = covtype_X_and_y.iloc[:, :-1]\n",
    "covtype_y = covtype_X_and_y.iloc[:, -1]\n",
    "\n",
    "covtype_y = covtype_y.map({7:1}).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "all_data_dict = {'wdbc':      (wdbc_X, wdbc_y),\n",
    "                 'income':    (income_X, income_y),\n",
    "                 'iris':      (iris_X, iris_y),\n",
    "                 'covtype':   (covtype_X, covtype_y),\n",
    "                 'letter':    (letter_X, letter_y)}\n",
    "\n",
    "size_info(all_data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Limit dataset sizes\n",
    "\n",
    "# Shuffle\n",
    "shuffled_data_dict = shuffle_data(all_data_dict, seed=RND_SEED)\n",
    "\n",
    "lim_data_dict = dict()\n",
    "for data_name, data_tuple in shuffled_data_dict.items():\n",
    "    X = data_tuple[0]\n",
    "    y = data_tuple[1]\n",
    "    \n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    if y.shape[0] > MAX_DATA_SIZE:\n",
    "        X = X.sample(MAX_DATA_SIZE, random_state=RND_SEED)\n",
    "        y = y.sample(MAX_DATA_SIZE, random_state=RND_SEED)\n",
    "\n",
    "    lim_data_dict[data_name] = (X, y)\n",
    "\n",
    "size_info(lim_data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Run big loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CLF_PARAM_DICT = {'knn':    {'n_neighbors':  np.arange(1, 31)},\n",
    "                  'rf':     {'n_estimators': np.array([1024]),\n",
    "                             'max_features': np.array([1, 2, 4, 6, 8, 12, 16, 20])},\n",
    "                  'logreg': {'C':            np.array([1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4])},\n",
    "                  'dt':     {'max_depth':    np.arange(1, 30),\n",
    "                             'max_features': np.arange(1, 30)},\n",
    "                  'bagdt':  {'n_estimators': np.arange(1, 30)},\n",
    "                  'bstdt':  {'n_estimators': np.arange(1, 30)}}\n",
    "\n",
    "\n",
    "TRAIN_SPLITS   = [0.2, 0.5, 0.8]\n",
    "N_SHUFFLES     = 3\n",
    "CV             = 5\n",
    "KNN_FILLUP     = 10\n",
    "\n",
    "# 4min 20 for knn, rf, logreg, dt, bagdt, bstdt; 1 shuffle  1 split\n",
    "# 30 min  for knn, rf, logreg, dt, bagdt, bstdt; 3 shuffles 3 splits\n",
    "\n",
    "loop = BigLoop(lim_data_dict, CLF_PARAM_DICT, TRAIN_SPLITS, N_SHUFFLES, CV,\n",
    "                  knn_fillup=KNN_FILLUP, method='grid_search', n_jobs=4)\n",
    "loop.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Big loop post processing for LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ### Load results from saved big loop\n",
    "# bigloop_loaded = BigLoop.load('2000_knn_rf_logreg_dt_bagdt_bstdt_3shu_3spl.pkl')\n",
    "# bigloop_train_scores = bigloop_loaded.splits_shuffles_train_scores_dict\n",
    "# bigloop_test_scores  = bigloop_loaded.splits_shuffles_test_scores_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# CLF_PARAM_DICT = {'knn':    {'n_neighbors':  np.arange(1, 31)},\n",
    "#                   'rf':     {'n_estimators': np.array([1024]),\n",
    "#                              'max_features': np.array([1, 2, 4, 6, 8, 12, 16, 20])},\n",
    "#                   'logreg': {'C':            np.array([1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4])},\n",
    "#                   'dt':     {'max_depth':    np.arange(1, 30),\n",
    "#                              'max_features': np.arange(1, 30)},\n",
    "#                   'bagdt':  {'n_estimators': np.arange(1, 30)},\n",
    "#                   'bstdt':  {'n_estimators': np.arange(1, 30)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### n_neighbors:30\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='knn', x_param_name='n_neighbors',\n",
    "                                       plot_train_split=0.8,\n",
    "                                       style_list=['ro-', 'gx-', 'b.-', 'y<-', 'c>-'])\n",
    "plt.xlim(0, 30)\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"K Nearest Neighors: k\")\n",
    "plt.legend(loc=4)\n",
    "plt.savefig('knn_hyperparam_zoomed.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### n_neighbors:all\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='knn', x_param_name='n_neighbors',\n",
    "                                       plot_train_split=0.8,\n",
    "                                       style_list=['r-', 'g-', 'b-', 'y-', 'c-'])\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"K Nearest Neighors: k\")\n",
    "plt.savefig('knn_hyperparam_all.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### rf: max_features\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='rf', x_param_name='max_features',\n",
    "                                       plot_train_split=0.8)\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Random Forest: max_features\")\n",
    "plt.xticks([1, 2, 4, 6, 8, 12, 16, 20])\n",
    "plt.savefig('rf_hyperparam.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### logreg: C\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='logreg', x_param_name='C',\n",
    "                                       plot_train_split=0.8)\n",
    "plt.xlabel(\"C\")\n",
    "plt.xscale('log')\n",
    "plt.xticks([1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4])\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Logistic Regression: C\")\n",
    "plt.savefig('logreg_hyperparam.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### dt: max_depth\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='dt', x_param_name='max_depth',\n",
    "                                       plot_train_split=0.8)\n",
    "plt.xlabel('max_depth')\n",
    "plt.title('Decision Tree: max_depth')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.savefig('dt_hyperparam_max_depth.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### dt: max_features\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='dt', x_param_name='max_features',\n",
    "                                       plot_train_split=0.8)\n",
    "plt.xlabel('max_features')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title('Decision Tree: max_features')\n",
    "plt.savefig('dt_hyperparam_max_features.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### baddt: n_estimators\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='bagdt', x_param_name='n_estimators',\n",
    "                                       plot_train_split=0.8)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title('Bagged Decision Trees: n_estimators')\n",
    "plt.savefig('bagdt_hyperparam.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### bstdt: n_estimators\n",
    "plot_avg_scores_by_hyperparam_data_clf(bigloop_loaded,\n",
    "                                       clf_name='bstdt', x_param_name='n_estimators',\n",
    "                                       plot_train_split=0.8)\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title('Boosted Decision Trees: n_estimators')\n",
    "plt.savefig('bstdt_hyperparam.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Creates LaTeX table with best hyperparam vals by clf and data\n",
    "\n",
    "## This part puts together best params from different shuffles as concatenated strings\n",
    "temp_dict = {}\n",
    "for shuffle_i, magicml_obj in enumerate(bigloop_loaded.magicml_dict[0.8]):\n",
    "    data_clf_dict = magicml_obj.best_params_dict\n",
    "    \n",
    "    for data_name, clf_dict in data_clf_dict.items():\n",
    "        if not data_name in temp_dict:\n",
    "            temp_dict[data_name] = dict()\n",
    "            \n",
    "        for clf_name, param_dict in clf_dict.items():\n",
    "            if not clf_name in temp_dict[data_name]:\n",
    "                temp_dict[data_name][clf_name] = dict()\n",
    "            \n",
    "            for param_name, param_val in param_dict.items():\n",
    "                if not param_name in temp_dict[data_name][clf_name]:\n",
    "                    temp_dict[data_name][clf_name][param_name] = \"\"\n",
    "                    \n",
    "                temp_dict[data_name][clf_name][param_name] += (',' + str(param_val))\n",
    "\n",
    "data_name_col = []\n",
    "clf_col = []\n",
    "param_name_col = []\n",
    "param_vals_col = []\n",
    "\n",
    "for data_name, clf_dict in temp_dict.items():\n",
    "    \n",
    "    for clf_name, param_dict in clf_dict.items():\n",
    "        \n",
    "        for param_name, param_vals in param_dict.items():\n",
    "            \n",
    "            data_name_col.append(data_name)\n",
    "            clf_col.append(clf_name)\n",
    "            param_name_col.append(param_name)\n",
    "            param_vals_col.append(param_vals.strip(','))\n",
    "            \n",
    "best_params_tbl_df_long = pd.DataFrame({'data_name': data_name_col,\n",
    "              'clf_name': clf_col,\n",
    "              'param_name': param_name_col,\n",
    "              'param_vals': param_vals_col})\n",
    "\n",
    "# Best function ever!\n",
    "def coolfun(x):\n",
    "    return(x)\n",
    "\n",
    "best_params_tbl_df = best_params_tbl_df_long.pivot_table(index=['clf_name', 'param_name'], values=['param_vals'], columns=['data_name'], aggfunc=coolfun)\n",
    "best_params_tbl_df\n",
    "\n",
    "# print(best_params_tbl_df.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data_param_vals_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Mean, SD across shuffles\n",
    "splits_shuffles_avg_train_scores_dict = dict()\n",
    "splits_shuffles_avg_test_scores_dict = dict()\n",
    "\n",
    "splits_shuffles_sd_train_scores_dict = dict()\n",
    "splits_shuffles_sd_test_scores_dict = dict()\n",
    "\n",
    "for train_split in bigloop_train_scores.keys():\n",
    "    split_shuffles_avg_train_scores_dict, split_shuffles_sd_train_scores_dict = \\\n",
    "        avg_sd_across_shuffles(bigloop_train_scores[train_split])\n",
    "    \n",
    "    split_shuffles_avg_test_scores_dict, split_shuffles_sd_test_scores_dict = \\\n",
    "        avg_sd_across_shuffles(bigloop_test_scores[train_split])\n",
    "        \n",
    "    splits_shuffles_avg_train_scores_dict[train_split] = split_shuffles_avg_train_scores_dict\n",
    "    splits_shuffles_avg_test_scores_dict[train_split]  = split_shuffles_avg_test_scores_dict\n",
    "    \n",
    "    splits_shuffles_sd_train_scores_dict[train_split]  = split_shuffles_sd_train_scores_dict\n",
    "    splits_shuffles_sd_test_scores_dict[train_split] = split_shuffles_sd_test_scores_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "splits_shuffles_avg_train_scores_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Average across data\n",
    "avg_train_scores_by_split_clf_dict = avg_clf_scores_across_data(splits_shuffles_avg_train_scores_dict)\n",
    "avg_test_scores_by_split_clf_dict  = avg_clf_scores_across_data(splits_shuffles_avg_test_scores_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avg_test_scores_by_split_clf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Plot train/test scores avg'ed across shuffles and datasets, by clf\n",
    "# Train/test accuracy averaged across random shuffles and data by clf\n",
    "\n",
    "# Plottable df\n",
    "avg_scores_by_split_cf_df = pd.DataFrame(columns = ['train_split',\n",
    "                                                   'clf_name',\n",
    "                                                   'accuracy_type',\n",
    "                                                   'accuracy'])\n",
    "\n",
    "for train_split, clf_score_dict in avg_train_scores_by_split_clf_dict.items():\n",
    "    for clf_name, score in clf_score_dict.items():\n",
    "        train_score_row = {'train_split':   train_split,\n",
    "                          'clf_name':      clf_name,\n",
    "                          'accuracy_type': 'train',\n",
    "                          'accuracy':      avg_train_scores_by_split_clf_dict[train_split][clf_name]}\n",
    "        test_score_row = {'train_split':   train_split,\n",
    "                          'clf_name':      clf_name,\n",
    "                          'accuracy_type': 'test',\n",
    "                          'accuracy':      avg_test_scores_by_split_clf_dict[train_split][clf_name]}\n",
    "        \n",
    "        avg_scores_by_split_cf_df = \\\n",
    "                avg_scores_by_split_cf_df.append(train_score_row, ignore_index=True)\n",
    "        avg_scores_by_split_cf_df = \\\n",
    "                avg_scores_by_split_cf_df.append(test_score_row, ignore_index=True)\n",
    "\n",
    "            \n",
    "# plt.figure()\n",
    "# sns_plot = sns.FacetGrid(avg_scores_by_split_cf_df, col='accuracy_type')\n",
    "# sns_plot.map(sns.pointplot, 'train_split', 'accuracy', 'clf_name')\n",
    "# sns_plot.add_legend()\n",
    "# plt.show()\n",
    "\n",
    "## Train\n",
    "train_plot_df = avg_scores_by_split_cf_df.loc[avg_scores_by_split_cf_df['accuracy_type'] == 'train', :]\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = sns.pointplot(x='train_split', y='accuracy', hue='clf_name',\n",
    "                   markers=['x', 'o', '.', 'v', '*', '^'],\n",
    "                   data=train_plot_df)\n",
    "ax.set_title('Training accuracy')\n",
    "ax.set(ylim=(0.8, 1.02))\n",
    "plt.savefig('latex/tr_acc_by_clf_trainsplit.pdf')\n",
    "plt.show()\n",
    "\n",
    "## Test\n",
    "train_plot_df = avg_scores_by_split_cf_df.loc[avg_scores_by_split_cf_df['accuracy_type'] == 'test', :]\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = sns.pointplot(x='train_split', y='accuracy', hue='clf_name',\n",
    "                   markers=['x', 'o', '.', 'v', '*', '^'],\n",
    "                   data=train_plot_df)\n",
    "ax.set_title('Testing accuracy')\n",
    "ax.set(ylim=(0.8, 1.02))\n",
    "plt.savefig('latex/te_acc_by_clf_trainsplit.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Classifier testing performance by dataset and clf, train_split=0.8\n",
    "test_score_by_data_clf_df = pd.DataFrame()\n",
    "\n",
    "for data_name, score_clf_dict in splits_shuffles_avg_test_scores_dict[0.8].items():\n",
    "    data_row = {'data_name': data_name}\n",
    "    for clf_name, score in score_clf_dict.items():\n",
    "        data_row[clf_name] = score\n",
    "    test_score_by_data_clf_df = test_score_by_data_clf_df.append(data_row, ignore_index=True)\n",
    "\n",
    "test_score_by_data_clf_df = test_score_by_data_clf_df.set_index('data_name')\n",
    "test_score_by_data_clf_df = test_score_by_data_clf_df.transpose()\n",
    "test_score_by_data_clf_df\n",
    "\n",
    "# def latex_f1(x):\n",
    "#     return(\"{0:.3f}\".format(x).lstrip('0'))\n",
    "# print(test_score_by_data_clf_df.to_latex(formatters=[latex_f1, latex_f1, latex_f1, latex_f1, latex_f1, latex_f1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Classifier ranking by overall average performance\n",
    "pd.DataFrame(test_score_by_data_clf_df.mean(axis=1).sort_values(ascending=False), columns=['Accuracy'])\n",
    "# print(pd.DataFrame(test_score_by_data_clf_df.mean(axis=1).sort_values(ascending=False), columns=['Accuracy']).to_latex(formatters=[latex_f1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "TODO:\n",
    "- Make object that hands back best classifier for dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
