{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Questions_\n",
    "- Large and small datasets, what is better: same relative or absolute train size?\n",
    "  (or choose subset of data a priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import string\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "MAX_DATA_SIZE = 1000\n",
    "\n",
    "RND_SEED = 1\n",
    "\n",
    "CLF_DICT       = {'logreg': linear_model.LogisticRegression(),\n",
    "                  'knn':    neighbors.KNeighborsClassifier(),\n",
    "                  'rf':     ensemble.RandomForestClassifier(),\n",
    "                  'svm':    svm.SVC()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Methods and classes\n",
    "\n",
    "def size_info():\n",
    "    ### Size info\n",
    "    print(\"Data sizes:\")\n",
    "    for data_name, data_tuple in all_data_dict.items():\n",
    "        print(\"\\n{}:\\nX: {}\\ny: {}\".format(data_name, data_tuple[0].shape, data_tuple[1].shape))\n",
    "\n",
    "def shuffle(df):\n",
    "    \"\"\"\n",
    "    Shuffles dataset using seed specified in RND_SEED (see config part above).\n",
    "    \n",
    "        df:  Dataset to be shuffled.\n",
    "        \n",
    "    Returns shuffled dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    return(df.sample(frac=1, random_state=np.random.RandomState(seed=RND_SEED)))\n",
    "\n",
    "def init_clf(clf_name, clf_dict=CLF_DICT):\n",
    "    return(copy.deepcopy(clf_dict[clf_name]))\n",
    "\n",
    "class MagicSearcher:\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds hyperparams for set of datasets and set of classifiers with specified hyperparam grids\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict       = None\n",
    "    clf_param_dict  = None\n",
    "    cv              = None\n",
    "    n_jobs          = None\n",
    "    verbose         = None\n",
    "    method          = None\n",
    "    \n",
    "    # Randomized Search\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    searcher_obj_dict = None\n",
    "    best_params_dict  = None\n",
    "    \n",
    "    def __init__(self, clf_param_dict, data_dict=None, cv=5, n_jobs=4, verbose=False, method='grid_search'):\n",
    "        self.data_dict      = data_dict\n",
    "        self.clf_param_dict = clf_param_dict\n",
    "        self.cv             = cv\n",
    "        self.n_jobs         = n_jobs\n",
    "        self.verbose        = verbose\n",
    "        self.method         = method\n",
    "        \n",
    "    def search(self, data_dict=None, n_iter=None):\n",
    "        if self.method == 'randomized_search' and n_iter is None:\n",
    "            raise Exception('You need to specify n_iter for randomized search')\n",
    "        self.n_iter = n_iter\n",
    "            \n",
    "        if (self.data_dict is None) and (data_dict is None):\n",
    "            raise Exception('You need to specify data!') \n",
    "        \n",
    "        searcher_obj_dict = dict()\n",
    "        best_params_dict = dict()\n",
    "        for data_name, data_tuple in self.data_dict.items():\n",
    "            print(\"Working on dataset {} ...\".format(data_name))\n",
    "            \n",
    "            X = data_tuple[0]\n",
    "            y = data_tuple[1]\n",
    "            \n",
    "            searcher_obj_dict[data_name] = dict()\n",
    "            best_params_dict[data_name] = dict()\n",
    "            for clf_name, param_dict in clf_param_dict.items():\n",
    "                print(\"  Doing {} magic ...\".format(clf_name))\n",
    "                searcher_obj = ParamSearcher(X, y, clf_name, param_dict, self.method, self.n_jobs, self.cv, self.verbose)\n",
    "                searcher_obj.search()\n",
    "                searcher_obj_dict[data_name][clf_name] = searcher_obj\n",
    "                \n",
    "                best_params_dict[data_name][clf_name] = searcher_obj.best_params_\n",
    "        self.searcher_obj_dict = searcher_obj_dict\n",
    "        self.best_params_dict = best_params_dict\n",
    "\n",
    "class ParamSearcher:\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds hyperparams for one dataset and one classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    clf_name = None\n",
    "    param_dict = None\n",
    "    method = None\n",
    "    verbose = None\n",
    "    n_jobs = None\n",
    "    cv = None\n",
    "    \n",
    "    # Randomized Search\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    skl_search_obj = None\n",
    "    best_params_ = None\n",
    "    \n",
    "    def __init__(self, X, y, clf_name, param_dict, method='grid_search', n_jobs=4, cv=5, verbose=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.clf_name = clf_name\n",
    "        self.param_dict = param_dict\n",
    "        self.method = method\n",
    "        self.n_jobs = n_jobs\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def check_params(self):\n",
    "        # Check for exceeded hard limits of some params\n",
    "        if self.clf_name == 'knn':\n",
    "            if 'n_neighbors' in self.param_dict:\n",
    "                max_n_neighbors = int(np.floor(self.X.shape[0]/self.cv)-1)\n",
    "                if np.any(self.param_dict['n_neighbors'] > max_n_neighbors):\n",
    "                    print('ParamSearcher: knn: some n_neighbors > n_samples/cv-1. Restricting range to n_samples/cv-1.')\n",
    "                    self.param_dict['n_neighbors'][self.param_dict['n_neighbors'] > max_n_neighbors] = max_n_neighbors\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['n_neighbors'] = np.unique(self.param_dict['n_neighbors'])\n",
    "        elif self.clf_name == 'rf':\n",
    "            if 'max_features' in self.param_dict:\n",
    "                if np.any(self.param_dict['max_features'] > self.X.shape[1]):\n",
    "                    print('ParamSearcher: rf: some max_features > n_features. Restricting range to max_features.')\n",
    "                    self.param_dict['max_features'][self.param_dict['max_features'] > self.X.shape[1]] = self.X.shape[1]\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['max_features'] = np.unique(self.param_dict['max_features'])\n",
    "                    \n",
    "                    \n",
    "    def search(self, n_iter=None):\n",
    "        self.check_params()\n",
    "        \n",
    "        if self.method == 'grid_search':\n",
    "            skl_search_obj = GridSearchCV(estimator  = init_clf(self.clf_name),\n",
    "                                          param_grid = self.param_dict,\n",
    "                                          n_jobs     = self.n_jobs,\n",
    "                                          cv         = self.cv,\n",
    "                                          verbose    = self.verbose)\n",
    "        elif self.method == 'randomized_search':\n",
    "            if n_iter is None:\n",
    "                raise Exception('You need to specify n_iter for randomized search')\n",
    "            self.n_iter = n_iter\n",
    "            \n",
    "            skl_search_obj = RandomizedSearchCV(estimator           = init_clf(self.clf_name),\n",
    "                                                 param_distributions = self.param_dict,\n",
    "                                                 n_iter              = n_iter,\n",
    "                                                 n_jobs              = self.n_jobs,\n",
    "                                                 cv                  = self.cv,\n",
    "                                                 verbose             = self.verbose)\n",
    "        skl_search_obj.fit(self.X, self.y)\n",
    "        self.skl_search_obj = skl_search_obj\n",
    "        self.best_params_ = skl_search_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes:\n",
      "\n",
      "wdbc:\n",
      "X: (569, 30)\n",
      "y: (569,)\n",
      "\n",
      "income:\n",
      "X: (32561, 108)\n",
      "y: (32561,)\n",
      "\n",
      "iris:\n",
      "X: (150, 4)\n",
      "y: (150,)\n",
      "\n",
      "covtype:\n",
      "X: (581011, 54)\n",
      "y: (581011,)\n",
      "\n",
      "letter:\n",
      "X: (20000, 16)\n",
      "y: (20000,)\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "## iris\n",
    "iris_X = pd.DataFrame(datasets.load_iris()['data'])\n",
    "iris_y = pd.Series(datasets.load_iris()['target'])\n",
    "\n",
    "\n",
    "## wdbc\n",
    "wdbc_X_and_y = pd.read_csv('data/wdbc.data', header = None).iloc[:, 1:] # drop ID, then first col = y\n",
    "wdbc_y = wdbc_X_and_y.iloc[:, 0]\n",
    "wdbc_X = wdbc_X_and_y.iloc[:, 1:]\n",
    "\n",
    "wdbc_y = wdbc_y.map({'B': -1, 'M': 1}) # Transform y from (B, M) to (-1, 1)\n",
    "\n",
    "\n",
    "## income\n",
    "# Load, prepare, and shuffle adult income data\n",
    "income_X_and_y = pd.read_csv('data/adult.data', header=None)\n",
    "income_X_and_y.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                         'marital-status', 'occupation', 'relationship',\n",
    "                         'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                         'native-country', 'income']\n",
    "\n",
    "# one-hot encode categorical variables\n",
    "income_categorical_vars = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'native-country']\n",
    "income_X_and_y_onehot = pd.DataFrame()\n",
    "for var in income_categorical_vars:\n",
    "    dummy_coded_var_df = pd.get_dummies(income_X_and_y[var], prefix=var)\n",
    "    income_X_and_y_onehot = pd.concat([income_X_and_y_onehot, dummy_coded_var_df], axis=1)\n",
    "\n",
    "# add remaining columns to one-hot encoded df\n",
    "income_X_and_y = pd.concat([income_X_and_y_onehot,\n",
    "                            income_X_and_y.loc[:, income_X_and_y.columns[\n",
    "                                np.logical_not(np.in1d(income_X_and_y.columns, income_categorical_vars))]]],\n",
    "                           axis=1)\n",
    "\n",
    "income_y = income_X_and_y.loc[:, 'income']\n",
    "income_X = income_X_and_y.drop('income', axis=1)\n",
    "\n",
    "# Transform y from (<=50K, >50K) to (-1, 1)\n",
    "income_y = income_y.map({' <=50K': -1, ' >50K': 1})\n",
    "\n",
    "\n",
    "## Letter\n",
    "letter_X_and_y = pd.read_csv('data/letter.data', header=None)\n",
    "letter_X = letter_X_and_y.iloc[:, 1:]\n",
    "letter_y = letter_X_and_y.iloc[:, 0]\n",
    "\n",
    "# Transform y from A:M -> -1 and N:Z -> 1\n",
    "def alph_to_cat(letter):\n",
    "    if str.upper(letter) in list(string.ascii_uppercase[:13]):\n",
    "        return(1)\n",
    "    elif str.upper(letter) in list(string.ascii_uppercase[13:]):\n",
    "        return(-1)\n",
    "    \n",
    "letter_y = letter_y.map(alph_to_cat)\n",
    "\n",
    "## covtype\n",
    "covtype_X_and_y = pd.read_csv('data/covtype.data')\n",
    "covtype_X = covtype_X_and_y.iloc[:, :-1]\n",
    "covtype_y = covtype_X_and_y.iloc[:, -1]\n",
    "\n",
    "covtype_y = covtype_y.map({7:1}).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "all_data_dict = {'wdbc':      (wdbc_X, wdbc_y),\n",
    "                 'income':    (income_X, income_y),\n",
    "                 'iris':      (iris_X, iris_y),\n",
    "                 'covtype':   (covtype_X, covtype_y),\n",
    "                 'letter':    (letter_X, letter_y)}\n",
    "\n",
    "### Shuffle\n",
    "for data_name, data_tuple in all_data_dict.items():\n",
    "    X = data_tuple[0]\n",
    "    y = data_tuple[1]\n",
    "    \n",
    "    X = shuffle(X)\n",
    "    y = shuffle(y)\n",
    "    \n",
    "    all_data_dict[data_name] = (X, y)\n",
    "\n",
    "size_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes:\n",
      "\n",
      "wdbc:\n",
      "X: (569, 30)\n",
      "y: (569,)\n",
      "\n",
      "income:\n",
      "X: (1000, 108)\n",
      "y: (1000,)\n",
      "\n",
      "iris:\n",
      "X: (150, 4)\n",
      "y: (150,)\n",
      "\n",
      "covtype:\n",
      "X: (1000, 54)\n",
      "y: (1000,)\n",
      "\n",
      "letter:\n",
      "X: (1000, 16)\n",
      "y: (1000,)\n"
     ]
    }
   ],
   "source": [
    "### Limit dataset sizes\n",
    "for data_name, data_tuple in all_data_dict.items():\n",
    "    X = data_tuple[0]\n",
    "    y = data_tuple[1]\n",
    "    \n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    if y.shape[0] > MAX_DATA_SIZE:\n",
    "        X = X.sample(MAX_DATA_SIZE, random_state=RND_SEED)\n",
    "        y = y.sample(MAX_DATA_SIZE, random_state=RND_SEED)\n",
    "\n",
    "        all_data_dict[data_name] = (X, y)\n",
    "\n",
    "size_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset wdbc ...\n",
      "  Doing knn magic ...\n",
      "  Doing rf magic ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8fb2af5cbaa8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMagicSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_param_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_data_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grid_search'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0meverything\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-e3587800e511>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, data_dict, n_iter)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"  Doing {} magic ...\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0msearcher_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParamSearcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0msearcher_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0msearcher_obj_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclf_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearcher_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e3587800e511>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, n_iter)\u001b[0m\n\u001b[1;32m    150\u001b[0m                                                  \u001b[0mcv\u001b[0m                  \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                                                  verbose             = self.verbose)\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mskl_search_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskl_search_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskl_search_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskl_search_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_more_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 tree = self._make_estimator(append=False,\n\u001b[0;32m--> 316\u001b[0;31m                                             random_state=random_state)\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/ensemble/base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0msub\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m         estimator.set_params(**dict((p, getattr(self, p))\n\u001b[1;32m    127\u001b[0m                                     for p in self.estimator_params))\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(estimator, safe)\u001b[0m\n\u001b[1;32m     58\u001b[0m                             % (repr(estimator), type(estimator)))\n\u001b[1;32m     59\u001b[0m     \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mnew_object_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m             \u001b[0;31m# We need deprecation warnings to always be on in order to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;31m# catch deprecated param values.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[1;32m    201\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0;32m--> 201\u001b[0;31m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.anaconda3/lib/python3.6/inspect.py\u001b[0m in \u001b[0;36mname\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2478\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_annotation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_annotation'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2480\u001b[0;31m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2481\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Go!\n",
    "# clf_param_dict = {'knn':    {'n_neighbors': np.arange(1, 51)},\n",
    "#                   'logreg': {'C': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]},\n",
    "#                   'rf':     {'n_estimators': [1024],\n",
    "#                              'max_features': [1, 2, 4, 6, 8, 12, 16, 20]}}\n",
    "# clf_param_dict = {'knn':    {'n_neighbors':  np.arange(1, 51)},\n",
    "#                   'rf':     {'n_estimators': np.array([1024]),\n",
    "#                              'max_features': np.array([1, 2, 4, 6, 8, 12, 16, 20])},\n",
    "#                   'svm':    {'kernel':       ['rbf', 'linear']}}\n",
    "clf_param_dict = {'knn':    {'n_neighbors':  np.arange(1, 51)},\n",
    "                  'rf':     {'n_estimators': np.array([1024]),\n",
    "                             'max_features': np.array([1, 2, 4, 6, 8, 12, 16, 20])}}\n",
    "\n",
    "\n",
    "everything = MagicSearcher(clf_param_dict, all_data_dict, cv=5, n_jobs=None, verbose=False, method='grid_search')\n",
    "everything.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/.anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.98000, std: 0.01633, params: {'kernel': 'rbf'}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla = everything.searcher_obj_dict['iris']['svm']\n",
    "bla.skl_search_obj.grid_scores_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
