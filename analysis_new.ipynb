{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Questions_\n",
    "- Large and small datasets, what is better: same relative or absolute train size?\n",
    "  (or choose subset of data a priori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Imports\n",
    "\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import string\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import neural_network\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Config\n",
    "\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "MAX_DATA_SIZE = 1000\n",
    "\n",
    "RND_SEED = 1\n",
    "\n",
    "CLF_DICT       = {'logreg': linear_model.LogisticRegression(),\n",
    "                  'knn':    neighbors.KNeighborsClassifier(),\n",
    "                  'rf':     ensemble.RandomForestClassifier(),\n",
    "                  'svm':    svm.SVC()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Methods and classes\n",
    "\n",
    "def size_info():\n",
    "    ### Size info\n",
    "    print(\"Data sizes:\")\n",
    "    for data_name, data_tuple in all_data_dict.items():\n",
    "        print(\"\\n{}:\\nX: {}\\ny: {}\".format(data_name, data_tuple[0].shape, data_tuple[1].shape))\n",
    "\n",
    "def shuffle(df):\n",
    "    \"\"\"\n",
    "    Shuffles dataset using seed specified in RND_SEED (see config part above).\n",
    "    \n",
    "        df:  Dataset to be shuffled.\n",
    "        \n",
    "    Returns shuffled dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    return(df.sample(frac=1, random_state=np.random.RandomState(seed=RND_SEED)))\n",
    "\n",
    "def init_clf(clf_name, clf_dict=CLF_DICT):\n",
    "    return(copy.deepcopy(clf_dict[clf_name]))\n",
    "\n",
    "class MagicSearcher:\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds hyperparams for set of datasets and set of classifiers with specified hyperparam grids\n",
    "    \"\"\"\n",
    "    \n",
    "    data_dict       = None\n",
    "    clf_param_dict  = None\n",
    "    cv              = None\n",
    "    n_jobs          = None\n",
    "    verbose         = None\n",
    "    method          = None\n",
    "    \n",
    "    # Randomized Search\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    searcher_obj_dict = None\n",
    "    best_params_dict  = None\n",
    "    scores_df         = None # Used for plotting\n",
    "    \n",
    "    def __init__(self, clf_param_dict, data_dict=None, cv=5, n_jobs=4, verbose=False, method='grid_search'):\n",
    "        self.data_dict      = data_dict\n",
    "        self.clf_param_dict = clf_param_dict\n",
    "        self.cv             = cv\n",
    "        self.n_jobs         = n_jobs\n",
    "        self.verbose        = verbose\n",
    "        self.method         = method\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(self, f, pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def create_scores_df(self):\n",
    "        # Prepare score df dict\n",
    "        clf_scores_df_dict = dict()\n",
    "        for clf_name, param_dict in self.clf_param_dict.items():\n",
    "            columns = ['data_name']\n",
    "            columns.extend(list(self.clf_param_dict[clf_name].keys()))\n",
    "            columns.extend(['scores_mean', 'scores_sd'])\n",
    "\n",
    "            clf_scores_df_dict[clf_name] = pd.DataFrame(columns=columns)\n",
    "\n",
    "        for data_name, clf_searcher_obj_dict in self.searcher_obj_dict.items():\n",
    "            for clf_name, searcher_obj in clf_searcher_obj_dict.items():\n",
    "                grid_scores = searcher_obj.skl_search_obj.grid_scores_\n",
    "\n",
    "                for grid_score in grid_scores:\n",
    "                    param_comb_dict = grid_score[0]\n",
    "                    scores_mean = np.mean(grid_score[2])\n",
    "                    scores_sd = np.std(grid_score[2])\n",
    "\n",
    "                    row = {'data_name': data_name,\n",
    "                           'scores_mean': scores_mean,\n",
    "                           'scores_sd': scores_sd}\n",
    "\n",
    "                    for param_name, param_val in param_comb_dict.items():\n",
    "                        row[param_name] = param_val\n",
    "\n",
    "                    clf_scores_df_dict[clf_name] = clf_scores_df_dict[clf_name].append(row, ignore_index = True)\n",
    "        self.scores_df = clf_scores_df_dict\n",
    "        \n",
    "    def search(self, data_dict=None, n_iter=None):\n",
    "        if self.method == 'randomized_search' and n_iter is None:\n",
    "            raise Exception('You need to specify n_iter for randomized search')\n",
    "        self.n_iter = n_iter\n",
    "            \n",
    "        if (self.data_dict is None) and (data_dict is None):\n",
    "            raise Exception('You need to specify data!') \n",
    "        \n",
    "        searcher_obj_dict = dict()\n",
    "        best_params_dict = dict()\n",
    "        for data_name, data_tuple in self.data_dict.items():\n",
    "            print(\"Working on dataset {} ...\".format(data_name))\n",
    "            \n",
    "            X = data_tuple[0]\n",
    "            y = data_tuple[1]\n",
    "            \n",
    "            searcher_obj_dict[data_name] = dict()\n",
    "            best_params_dict[data_name] = dict()\n",
    "            for clf_name, param_dict in clf_param_dict.items():\n",
    "                print(\"  Doing {} magic ...\".format(clf_name))\n",
    "                searcher_obj = ParamSearcher(X, y, clf_name, param_dict, self.method, self.n_jobs, self.cv, self.verbose)\n",
    "                searcher_obj.search()\n",
    "                searcher_obj_dict[data_name][clf_name] = searcher_obj\n",
    "                \n",
    "                best_params_dict[data_name][clf_name] = searcher_obj.best_params_\n",
    "        self.searcher_obj_dict = searcher_obj_dict\n",
    "        self.best_params_dict = best_params_dict\n",
    "        \n",
    "        self.create_scores_df()\n",
    "\n",
    "class ParamSearcher:\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds hyperparams for one dataset and one classifier\n",
    "    \"\"\"\n",
    "    \n",
    "    X = None\n",
    "    y = None\n",
    "    clf_name = None\n",
    "    param_dict = None\n",
    "    method = None\n",
    "    verbose = None\n",
    "    n_jobs = None\n",
    "    cv = None\n",
    "    \n",
    "    # Randomized Search\n",
    "    n_iter = None\n",
    "    \n",
    "    # Results\n",
    "    skl_search_obj = None\n",
    "    best_params_ = None\n",
    "    \n",
    "    def __init__(self, X, y, clf_name, param_dict, method='grid_search', n_jobs=4, cv=5, verbose=False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.clf_name = clf_name\n",
    "        self.param_dict = param_dict\n",
    "        self.method = method\n",
    "        self.n_jobs = n_jobs\n",
    "        self.cv = cv\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def check_params(self):\n",
    "        # Check for exceeded hard limits of some params\n",
    "        if self.clf_name == 'knn':\n",
    "            if 'n_neighbors' in self.param_dict:\n",
    "                max_n_neighbors = int(np.floor(self.X.shape[0]/self.cv)-1)\n",
    "                if np.any(self.param_dict['n_neighbors'] > max_n_neighbors):\n",
    "                    print('ParamSearcher: knn: some n_neighbors > n_samples/cv-1. Restricting range to n_samples/cv-1.')\n",
    "                    self.param_dict['n_neighbors'][self.param_dict['n_neighbors'] > max_n_neighbors] = max_n_neighbors\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['n_neighbors'] = np.unique(self.param_dict['n_neighbors'])\n",
    "        elif self.clf_name == 'rf':\n",
    "            if 'max_features' in self.param_dict:\n",
    "                if np.any(self.param_dict['max_features'] > self.X.shape[1]):\n",
    "                    print('ParamSearcher: rf: some max_features > n_features. Restricting range to max_features.')\n",
    "                    self.param_dict['max_features'][self.param_dict['max_features'] > self.X.shape[1]] = self.X.shape[1]\n",
    "                    \n",
    "                    # Remove duplicates\n",
    "                    self.param_dict['max_features'] = np.unique(self.param_dict['max_features'])\n",
    "                    \n",
    "                    \n",
    "    def search(self, n_iter=None):\n",
    "        self.check_params()\n",
    "        \n",
    "        if self.method == 'grid_search':\n",
    "            skl_search_obj = GridSearchCV(estimator  = init_clf(self.clf_name),\n",
    "                                          param_grid = self.param_dict,\n",
    "                                          n_jobs     = self.n_jobs,\n",
    "                                          cv         = self.cv,\n",
    "                                          verbose    = self.verbose)\n",
    "        elif self.method == 'randomized_search':\n",
    "            if n_iter is None:\n",
    "                raise Exception('You need to specify n_iter for randomized search')\n",
    "            self.n_iter = n_iter\n",
    "            \n",
    "            skl_search_obj = RandomizedSearchCV(estimator           = init_clf(self.clf_name),\n",
    "                                                 param_distributions = self.param_dict,\n",
    "                                                 n_iter              = n_iter,\n",
    "                                                 n_jobs              = self.n_jobs,\n",
    "                                                 cv                  = self.cv,\n",
    "                                                 verbose             = self.verbose)\n",
    "        skl_search_obj.fit(self.X, self.y)\n",
    "        self.skl_search_obj = skl_search_obj\n",
    "        self.best_params_ = skl_search_obj.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes:\n",
      "\n",
      "wdbc:\n",
      "X: (569, 30)\n",
      "y: (569,)\n",
      "\n",
      "income:\n",
      "X: (32561, 108)\n",
      "y: (32561,)\n",
      "\n",
      "iris:\n",
      "X: (150, 4)\n",
      "y: (150,)\n",
      "\n",
      "covtype:\n",
      "X: (581011, 54)\n",
      "y: (581011,)\n",
      "\n",
      "letter:\n",
      "X: (20000, 16)\n",
      "y: (20000,)\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "## iris\n",
    "iris_X = pd.DataFrame(datasets.load_iris()['data'])\n",
    "iris_y = pd.Series(datasets.load_iris()['target'])\n",
    "\n",
    "\n",
    "## wdbc\n",
    "wdbc_X_and_y = pd.read_csv('data/wdbc.data', header = None).iloc[:, 1:] # drop ID, then first col = y\n",
    "wdbc_y = wdbc_X_and_y.iloc[:, 0]\n",
    "wdbc_X = wdbc_X_and_y.iloc[:, 1:]\n",
    "\n",
    "wdbc_y = wdbc_y.map({'B': -1, 'M': 1}) # Transform y from (B, M) to (-1, 1)\n",
    "\n",
    "\n",
    "## income\n",
    "# Load, prepare, and shuffle adult income data\n",
    "income_X_and_y = pd.read_csv('data/adult.data', header=None)\n",
    "income_X_and_y.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
    "                         'marital-status', 'occupation', 'relationship',\n",
    "                         'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
    "                         'native-country', 'income']\n",
    "\n",
    "# one-hot encode categorical variables\n",
    "income_categorical_vars = ['workclass', 'education', 'marital-status', 'occupation',\n",
    "                           'relationship', 'race', 'sex', 'native-country']\n",
    "income_X_and_y_onehot = pd.DataFrame()\n",
    "for var in income_categorical_vars:\n",
    "    dummy_coded_var_df = pd.get_dummies(income_X_and_y[var], prefix=var)\n",
    "    income_X_and_y_onehot = pd.concat([income_X_and_y_onehot, dummy_coded_var_df], axis=1)\n",
    "\n",
    "# add remaining columns to one-hot encoded df\n",
    "income_X_and_y = pd.concat([income_X_and_y_onehot,\n",
    "                            income_X_and_y.loc[:, income_X_and_y.columns[\n",
    "                                np.logical_not(np.in1d(income_X_and_y.columns, income_categorical_vars))]]],\n",
    "                           axis=1)\n",
    "\n",
    "income_y = income_X_and_y.loc[:, 'income']\n",
    "income_X = income_X_and_y.drop('income', axis=1)\n",
    "\n",
    "# Transform y from (<=50K, >50K) to (-1, 1)\n",
    "income_y = income_y.map({' <=50K': -1, ' >50K': 1})\n",
    "\n",
    "\n",
    "## Letter\n",
    "letter_X_and_y = pd.read_csv('data/letter.data', header=None)\n",
    "letter_X = letter_X_and_y.iloc[:, 1:]\n",
    "letter_y = letter_X_and_y.iloc[:, 0]\n",
    "\n",
    "# Transform y from A:M -> -1 and N:Z -> 1\n",
    "def alph_to_cat(letter):\n",
    "    if str.upper(letter) in list(string.ascii_uppercase[:13]):\n",
    "        return(1)\n",
    "    elif str.upper(letter) in list(string.ascii_uppercase[13:]):\n",
    "        return(-1)\n",
    "    \n",
    "letter_y = letter_y.map(alph_to_cat)\n",
    "\n",
    "## covtype\n",
    "covtype_X_and_y = pd.read_csv('data/covtype.data')\n",
    "covtype_X = covtype_X_and_y.iloc[:, :-1]\n",
    "covtype_y = covtype_X_and_y.iloc[:, -1]\n",
    "\n",
    "covtype_y = covtype_y.map({7:1}).fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "all_data_dict = {'wdbc':      (wdbc_X, wdbc_y),\n",
    "                 'income':    (income_X, income_y),\n",
    "                 'iris':      (iris_X, iris_y),\n",
    "                 'covtype':   (covtype_X, covtype_y),\n",
    "                 'letter':    (letter_X, letter_y)}\n",
    "\n",
    "### Shuffle\n",
    "for data_name, data_tuple in all_data_dict.items():\n",
    "    X = data_tuple[0]\n",
    "    y = data_tuple[1]\n",
    "    \n",
    "    X = shuffle(X)\n",
    "    y = shuffle(y)\n",
    "    \n",
    "    all_data_dict[data_name] = (X, y)\n",
    "\n",
    "size_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data sizes:\n",
      "\n",
      "wdbc:\n",
      "X: (569, 30)\n",
      "y: (569,)\n",
      "\n",
      "income:\n",
      "X: (1000, 108)\n",
      "y: (1000,)\n",
      "\n",
      "iris:\n",
      "X: (150, 4)\n",
      "y: (150,)\n",
      "\n",
      "covtype:\n",
      "X: (1000, 54)\n",
      "y: (1000,)\n",
      "\n",
      "letter:\n",
      "X: (1000, 16)\n",
      "y: (1000,)\n"
     ]
    }
   ],
   "source": [
    "### Limit dataset sizes\n",
    "for data_name, data_tuple in all_data_dict.items():\n",
    "    X = data_tuple[0]\n",
    "    y = data_tuple[1]\n",
    "    \n",
    "    assert X.shape[0] == y.shape[0]\n",
    "    \n",
    "    if y.shape[0] > MAX_DATA_SIZE:\n",
    "        X = X.sample(MAX_DATA_SIZE, random_state=RND_SEED)\n",
    "        y = y.sample(MAX_DATA_SIZE, random_state=RND_SEED)\n",
    "\n",
    "        all_data_dict[data_name] = (X, y)\n",
    "\n",
    "size_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on dataset wdbc ...\n",
      "  Doing knn magic ...\n",
      "  Doing rf magic ...\n",
      "Working on dataset income ...\n",
      "  Doing knn magic ...\n",
      "  Doing rf magic ...\n",
      "Working on dataset iris ...\n",
      "  Doing knn magic ...\n",
      "  Doing rf magic ...\n",
      "ParamSearcher: rf: some max_features > n_features. Restricting range to max_features.\n",
      "Working on dataset covtype ...\n",
      "  Doing knn magic ...\n",
      "  Doing rf magic ...\n",
      "Working on dataset letter ...\n",
      "  Doing knn magic ...\n",
      "  Doing rf magic ...\n"
     ]
    }
   ],
   "source": [
    "### Go!\n",
    "# clf_param_dict = {'knn':    {'n_neighbors': np.arange(1, 51)},\n",
    "#                   'logreg': {'C': [1e-8, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4]},\n",
    "#                   'rf':     {'n_estimators': [1024],\n",
    "#                              'max_features': [1, 2, 4, 6, 8, 12, 16, 20]}}\n",
    "# clf_param_dict = {'knn':    {'n_neighbors':  np.arange(1, 51)},\n",
    "#                   'rf':     {'n_estimators': np.array([1024]),\n",
    "#                              'max_features': np.array([1, 2, 4, 6, 8, 12, 16, 20])},\n",
    "#                   'svm':    {'kernel':       ['rbf', 'linear']}}\n",
    "clf_param_dict = {'knn':    {'n_neighbors':  np.arange(1, 51)},\n",
    "                  'rf':     {'n_estimators': np.array([256]),\n",
    "                             'max_features': np.array([1, 2, 4, 6])}}\n",
    "\n",
    "\n",
    "everything = MagicSearcher(clf_param_dict, all_data_dict, cv=2, n_jobs=None, verbose=False, method='grid_search')\n",
    "everything.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn':     data_name n_neighbors  scores_mean  scores_sd\n",
       " 0        wdbc           1     0.919193   0.020948\n",
       " 1        wdbc           2     0.910434   0.036749\n",
       " 2        wdbc           3     0.920948   0.019193\n",
       " 3        wdbc           4     0.912157   0.017420\n",
       " 4        wdbc           5     0.919181   0.013918\n",
       " 5        wdbc           6     0.920935   0.012163\n",
       " 6        wdbc           7     0.922702   0.017439\n",
       " 7        wdbc           8     0.919181   0.013918\n",
       " 8        wdbc           9     0.926211   0.013930\n",
       " 9        wdbc          10     0.927965   0.012176\n",
       " 10       wdbc          11     0.926205   0.010415\n",
       " 11       wdbc          12     0.924450   0.012170\n",
       " 12       wdbc          13     0.927965   0.012176\n",
       " 13       wdbc          14     0.922683   0.006894\n",
       " 14       wdbc          15     0.922690   0.010409\n",
       " 15       wdbc          16     0.917420   0.012157\n",
       " 16       wdbc          17     0.917420   0.012157\n",
       " 17       wdbc          18     0.917420   0.012157\n",
       " 18       wdbc          19     0.917420   0.012157\n",
       " 19       wdbc          20     0.913899   0.008636\n",
       " 20       wdbc          21     0.915660   0.010397\n",
       " 21       wdbc          22     0.910378   0.005115\n",
       " 22       wdbc          23     0.906869   0.008624\n",
       " 23       wdbc          24     0.906863   0.005109\n",
       " 24       wdbc          25     0.908617   0.003354\n",
       " 25       wdbc          26     0.908624   0.006869\n",
       " 26       wdbc          27     0.906863   0.005109\n",
       " 27       wdbc          28     0.906863   0.005109\n",
       " 28       wdbc          29     0.903354   0.008617\n",
       " 29       wdbc          30     0.905109   0.006863\n",
       " ..        ...         ...          ...        ...\n",
       " 220    letter          21     0.723000   0.013000\n",
       " 221    letter          22     0.720000   0.008000\n",
       " 222    letter          23     0.726000   0.000000\n",
       " 223    letter          24     0.717000   0.001000\n",
       " 224    letter          25     0.734000   0.000000\n",
       " 225    letter          26     0.720000   0.014000\n",
       " 226    letter          27     0.722000   0.016000\n",
       " 227    letter          28     0.710000   0.016000\n",
       " 228    letter          29     0.725000   0.019000\n",
       " 229    letter          30     0.700000   0.020000\n",
       " 230    letter          31     0.711000   0.031000\n",
       " 231    letter          32     0.693000   0.017000\n",
       " 232    letter          33     0.706000   0.030000\n",
       " 233    letter          34     0.693000   0.031000\n",
       " 234    letter          35     0.703000   0.029000\n",
       " 235    letter          36     0.694000   0.022000\n",
       " 236    letter          37     0.704000   0.020000\n",
       " 237    letter          38     0.685000   0.017000\n",
       " 238    letter          39     0.692000   0.016000\n",
       " 239    letter          40     0.688000   0.012000\n",
       " 240    letter          41     0.695000   0.021000\n",
       " 241    letter          42     0.691000   0.025000\n",
       " 242    letter          43     0.694000   0.030000\n",
       " 243    letter          44     0.691000   0.019000\n",
       " 244    letter          45     0.691000   0.021000\n",
       " 245    letter          46     0.686000   0.028000\n",
       " 246    letter          47     0.692000   0.028000\n",
       " 247    letter          48     0.704000   0.026000\n",
       " 248    letter          49     0.692000   0.030000\n",
       " 249    letter          50     0.698000   0.022000\n",
       " \n",
       " [250 rows x 4 columns],\n",
       " 'rf':    data_name n_estimators max_features  scores_mean  scores_sd\n",
       " 0       wdbc          256            1     0.949061   0.015728\n",
       " 1       wdbc          256            2     0.954330   0.013979\n",
       " 2       wdbc          256            4     0.949061   0.015728\n",
       " 3       wdbc          256            6     0.947313   0.020997\n",
       " 4     income          256            1     0.832023   0.011664\n",
       " 5     income          256            2     0.830019   0.009660\n",
       " 6     income          256            4     0.824019   0.009648\n",
       " 7     income          256            6     0.835013   0.006670\n",
       " 8       iris          256            1     0.960000   0.013333\n",
       " 9       iris          256            2     0.953333   0.020000\n",
       " 10      iris          256            4     0.953333   0.020000\n",
       " 11   covtype          256            1     0.968000   0.000000\n",
       " 12   covtype          256            2     0.969000   0.001000\n",
       " 13   covtype          256            4     0.968000   0.000000\n",
       " 14    letter          256            1     0.827000   0.027000\n",
       " 15    letter          256            2     0.838000   0.028000\n",
       " 16    letter          256            4     0.829000   0.019000}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything.scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "everything.save('knn_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loaded = MagicSearcher.load('./knn_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.95333, std: 0.02000, params: {'n_neighbors': 1},\n",
       " mean: 0.94667, std: 0.00000, params: {'n_neighbors': 2},\n",
       " mean: 0.96000, std: 0.00000, params: {'n_neighbors': 3},\n",
       " mean: 0.94667, std: 0.01333, params: {'n_neighbors': 4},\n",
       " mean: 0.96000, std: 0.01333, params: {'n_neighbors': 5},\n",
       " mean: 0.95333, std: 0.00667, params: {'n_neighbors': 6},\n",
       " mean: 0.94667, std: 0.01333, params: {'n_neighbors': 7},\n",
       " mean: 0.95333, std: 0.02000, params: {'n_neighbors': 8},\n",
       " mean: 0.96000, std: 0.01333, params: {'n_neighbors': 9},\n",
       " mean: 0.96000, std: 0.01333, params: {'n_neighbors': 10},\n",
       " mean: 0.96667, std: 0.02000, params: {'n_neighbors': 11},\n",
       " mean: 0.96667, std: 0.02000, params: {'n_neighbors': 12},\n",
       " mean: 0.97333, std: 0.01333, params: {'n_neighbors': 13},\n",
       " mean: 0.96667, std: 0.02000, params: {'n_neighbors': 14},\n",
       " mean: 0.96667, std: 0.02000, params: {'n_neighbors': 15},\n",
       " mean: 0.95333, std: 0.00667, params: {'n_neighbors': 16},\n",
       " mean: 0.95333, std: 0.02000, params: {'n_neighbors': 17},\n",
       " mean: 0.94667, std: 0.02667, params: {'n_neighbors': 18},\n",
       " mean: 0.96000, std: 0.02667, params: {'n_neighbors': 19},\n",
       " mean: 0.94667, std: 0.01333, params: {'n_neighbors': 20},\n",
       " mean: 0.94667, std: 0.02667, params: {'n_neighbors': 21},\n",
       " mean: 0.93333, std: 0.02667, params: {'n_neighbors': 22},\n",
       " mean: 0.94000, std: 0.03333, params: {'n_neighbors': 23},\n",
       " mean: 0.94000, std: 0.03333, params: {'n_neighbors': 24},\n",
       " mean: 0.93333, std: 0.02667, params: {'n_neighbors': 25},\n",
       " mean: 0.92667, std: 0.03333, params: {'n_neighbors': 26},\n",
       " mean: 0.92000, std: 0.04000, params: {'n_neighbors': 27},\n",
       " mean: 0.91333, std: 0.03333, params: {'n_neighbors': 28},\n",
       " mean: 0.92667, std: 0.03333, params: {'n_neighbors': 29},\n",
       " mean: 0.92667, std: 0.02000, params: {'n_neighbors': 30},\n",
       " mean: 0.92667, std: 0.03333, params: {'n_neighbors': 31},\n",
       " mean: 0.92000, std: 0.04000, params: {'n_neighbors': 32},\n",
       " mean: 0.92000, std: 0.04000, params: {'n_neighbors': 33},\n",
       " mean: 0.90667, std: 0.01333, params: {'n_neighbors': 34},\n",
       " mean: 0.92000, std: 0.02667, params: {'n_neighbors': 35},\n",
       " mean: 0.90667, std: 0.01333, params: {'n_neighbors': 36},\n",
       " mean: 0.92667, std: 0.03333, params: {'n_neighbors': 37},\n",
       " mean: 0.92667, std: 0.03333, params: {'n_neighbors': 38},\n",
       " mean: 0.92000, std: 0.02667, params: {'n_neighbors': 39},\n",
       " mean: 0.91333, std: 0.03333, params: {'n_neighbors': 40},\n",
       " mean: 0.92000, std: 0.02667, params: {'n_neighbors': 41},\n",
       " mean: 0.90667, std: 0.04000, params: {'n_neighbors': 42},\n",
       " mean: 0.90000, std: 0.03333, params: {'n_neighbors': 43},\n",
       " mean: 0.89333, std: 0.02667, params: {'n_neighbors': 44},\n",
       " mean: 0.86667, std: 0.00000, params: {'n_neighbors': 45},\n",
       " mean: 0.88000, std: 0.01333, params: {'n_neighbors': 46},\n",
       " mean: 0.87333, std: 0.00667, params: {'n_neighbors': 47},\n",
       " mean: 0.88000, std: 0.04000, params: {'n_neighbors': 48},\n",
       " mean: 0.90000, std: 0.02000, params: {'n_neighbors': 49},\n",
       " mean: 0.66000, std: 0.00667, params: {'n_neighbors': 50}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bla = loaded.searcher_obj_dict['iris']['knn']\n",
    "bla.skl_search_obj.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MagicSearcher.load('./knn_rf.pkl')\n",
    "\n",
    "# Prepare score df dict\n",
    "clf_scores_df_dict = dict()\n",
    "for clf_name, param_dict in ms.clf_param_dict.items():\n",
    "    columns = ['data_name']\n",
    "    columns.extend(list(ms.clf_param_dict[clf_name].keys()))\n",
    "    columns.extend(['scores_mean', 'scores_sd'])\n",
    "    \n",
    "    clf_scores_df_dict[clf_name] = pd.DataFrame(columns=columns)\n",
    "\n",
    "for data_name, clf_searcher_obj_dict in ms.searcher_obj_dict.items():\n",
    "    for clf_name, searcher_obj in clf_searcher_obj_dict.items():\n",
    "        grid_scores = searcher_obj.skl_search_obj.grid_scores_\n",
    "        \n",
    "        for grid_score in grid_scores:\n",
    "            param_comb_dict = grid_score[0]\n",
    "            scores_mean = np.mean(grid_score[2])\n",
    "            scores_sd = np.std(grid_score[2])\n",
    "            \n",
    "            row = {'data_name': data_name,\n",
    "                   'scores_mean': scores_mean,\n",
    "                   'scores_sd': scores_sd}\n",
    "            \n",
    "            for param_name, param_val in param_comb_dict.items():\n",
    "                row[param_name] = param_val\n",
    "                \n",
    "            clf_scores_df_dict[clf_name] = clf_scores_df_dict[clf_name].append(row, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'knn':     data_name n_neighbors  scores_mean  scores_sd\n",
       " 0        wdbc           1     0.919193   0.020948\n",
       " 1        wdbc           2     0.910434   0.036749\n",
       " 2        wdbc           3     0.920948   0.019193\n",
       " 3        wdbc           4     0.912157   0.017420\n",
       " 4        wdbc           5     0.919181   0.013918\n",
       " 5        wdbc           6     0.920935   0.012163\n",
       " 6        wdbc           7     0.922702   0.017439\n",
       " 7        wdbc           8     0.919181   0.013918\n",
       " 8        wdbc           9     0.926211   0.013930\n",
       " 9        wdbc          10     0.927965   0.012176\n",
       " 10       wdbc          11     0.926205   0.010415\n",
       " 11       wdbc          12     0.924450   0.012170\n",
       " 12       wdbc          13     0.927965   0.012176\n",
       " 13       wdbc          14     0.922683   0.006894\n",
       " 14       wdbc          15     0.922690   0.010409\n",
       " 15       wdbc          16     0.917420   0.012157\n",
       " 16       wdbc          17     0.917420   0.012157\n",
       " 17       wdbc          18     0.917420   0.012157\n",
       " 18       wdbc          19     0.917420   0.012157\n",
       " 19       wdbc          20     0.913899   0.008636\n",
       " 20       wdbc          21     0.915660   0.010397\n",
       " 21       wdbc          22     0.910378   0.005115\n",
       " 22       wdbc          23     0.906869   0.008624\n",
       " 23       wdbc          24     0.906863   0.005109\n",
       " 24       wdbc          25     0.908617   0.003354\n",
       " 25       wdbc          26     0.908624   0.006869\n",
       " 26       wdbc          27     0.906863   0.005109\n",
       " 27       wdbc          28     0.906863   0.005109\n",
       " 28       wdbc          29     0.903354   0.008617\n",
       " 29       wdbc          30     0.905109   0.006863\n",
       " ..        ...         ...          ...        ...\n",
       " 220    letter          21     0.723000   0.013000\n",
       " 221    letter          22     0.720000   0.008000\n",
       " 222    letter          23     0.726000   0.000000\n",
       " 223    letter          24     0.717000   0.001000\n",
       " 224    letter          25     0.734000   0.000000\n",
       " 225    letter          26     0.720000   0.014000\n",
       " 226    letter          27     0.722000   0.016000\n",
       " 227    letter          28     0.710000   0.016000\n",
       " 228    letter          29     0.725000   0.019000\n",
       " 229    letter          30     0.700000   0.020000\n",
       " 230    letter          31     0.711000   0.031000\n",
       " 231    letter          32     0.693000   0.017000\n",
       " 232    letter          33     0.706000   0.030000\n",
       " 233    letter          34     0.693000   0.031000\n",
       " 234    letter          35     0.703000   0.029000\n",
       " 235    letter          36     0.694000   0.022000\n",
       " 236    letter          37     0.704000   0.020000\n",
       " 237    letter          38     0.685000   0.017000\n",
       " 238    letter          39     0.692000   0.016000\n",
       " 239    letter          40     0.688000   0.012000\n",
       " 240    letter          41     0.695000   0.021000\n",
       " 241    letter          42     0.691000   0.025000\n",
       " 242    letter          43     0.694000   0.030000\n",
       " 243    letter          44     0.691000   0.019000\n",
       " 244    letter          45     0.691000   0.021000\n",
       " 245    letter          46     0.686000   0.028000\n",
       " 246    letter          47     0.692000   0.028000\n",
       " 247    letter          48     0.704000   0.026000\n",
       " 248    letter          49     0.692000   0.030000\n",
       " 249    letter          50     0.698000   0.022000\n",
       " \n",
       " [250 rows x 4 columns],\n",
       " 'rf':    data_name n_estimators max_features  scores_mean  scores_sd\n",
       " 0       wdbc          256            1     0.949067   0.019243\n",
       " 1       wdbc          256            2     0.952582   0.019249\n",
       " 2       wdbc          256            4     0.952582   0.019249\n",
       " 3       wdbc          256            6     0.950828   0.021003\n",
       " 4     income          256            1     0.832015   0.007664\n",
       " 5     income          256            2     0.827013   0.006654\n",
       " 6     income          256            4     0.836011   0.005672\n",
       " 7     income          256            6     0.840011   0.005680\n",
       " 8       iris          256            1     0.953333   0.020000\n",
       " 9       iris          256            2     0.960000   0.013333\n",
       " 10      iris          256            4     0.953333   0.020000\n",
       " 11   covtype          256            1     0.968000   0.000000\n",
       " 12   covtype          256            2     0.968000   0.000000\n",
       " 13   covtype          256            4     0.969000   0.001000\n",
       " 14    letter          256            1     0.823000   0.029000\n",
       " 15    letter          256            2     0.832000   0.018000\n",
       " 16    letter          256            4     0.831000   0.031000}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_scores_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_name': 'letter', 'knn': Empty DataFrame\n",
       " Columns: [data_name, scores_mean, scores_sd]\n",
       " Index: [], 'max_features': 4, 'n_estimators': 256, 'n_neighbors': 50, 'rf': Empty DataFrame\n",
       " Columns: [data_name, scores_mean, scores_sd]\n",
       " Index: [], 'scores_mean': 0.83099999999999996, 'scores_sd': 0.030999999999999972}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_scores_df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.82300, std: 0.02900, params: {'max_features': 1, 'n_estimators': 256},\n",
       " mean: 0.83200, std: 0.01800, params: {'max_features': 2, 'n_estimators': 256},\n",
       " mean: 0.83100, std: 0.03100, params: {'max_features': 4, 'n_estimators': 256}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = searcher_obj.skl_search_obj.grid_scores_\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean: 0.83100, std: 0.03100, params: {'max_features': 4, 'n_estimators': 256}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 4, 'n_estimators': 256}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.8  ,  0.862])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
