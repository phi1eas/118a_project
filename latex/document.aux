\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\bibstyle{plainnat}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Method}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment (Results)}{1}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Hyperparameters and Performance}{1}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Train/Test split and Performance}{1}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Overall Classifier Performance}{1}{subsection.3.3}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:hyperparam_knn_zoomed}{{1a}{2}{KNN: \textit {k}\relax }{figure.caption.1}{}}
\newlabel{sub@fig:hyperparam_knn_zoomed}{{a}{2}{KNN: \textit {k}\relax }{figure.caption.1}{}}
\newlabel{fig:hyperparam_knn_all}{{1b}{2}{KNN: \textit {k}\relax }{figure.caption.1}{}}
\newlabel{sub@fig:hyperparam_knn_all}{{b}{2}{KNN: \textit {k}\relax }{figure.caption.1}{}}
\newlabel{fig:hyperparam_dt_max_depth}{{1c}{2}{Decision Tree: \textit {max\_depth}\relax }{figure.caption.1}{}}
\newlabel{sub@fig:hyperparam_dt_max_depth}{{c}{2}{Decision Tree: \textit {max\_depth}\relax }{figure.caption.1}{}}
\newlabel{fig:hyperparam_dt_max_features}{{1d}{2}{Decision Tree: \textit {max\_features}\relax }{figure.caption.1}{}}
\newlabel{sub@fig:hyperparam_dt_max_features}{{d}{2}{Decision Tree: \textit {max\_features}\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Validation score by hyperparameter value for KNN (\ref  {fig:hyperparam_knn_zoomed} and \ref  {fig:hyperparam_knn_all}) and Decision Tree (\ref  {fig:hyperparam_dt_max_depth} and \ref  {fig:hyperparam_dt_max_features}), averaged over data, shuffles, and train split. \ref  {fig:hyperparam_knn_zoomed} zooms in on a subset of the results shown in \ref  {fig:hyperparam_dt_max_depth} for greater detail. \ref  {fig:hyperparam_dt_max_depth} depicts results for varying levels of \textit  {max\_depth}, averaged over \textit  {max\_features}, wheres the opposite is done in \ref  {fig:hyperparam_dt_max_depth}.\relax }}{2}{figure.caption.1}}
\newlabel{fig:hyperparam_knn_dt}{{1}{2}{Validation score by hyperparameter value for KNN (\ref {fig:hyperparam_knn_zoomed} and \ref {fig:hyperparam_knn_all}) and Decision Tree (\ref {fig:hyperparam_dt_max_depth} and \ref {fig:hyperparam_dt_max_features}), averaged over data, shuffles, and train split. \ref {fig:hyperparam_knn_zoomed} zooms in on a subset of the results shown in \ref {fig:hyperparam_dt_max_depth} for greater detail. \ref {fig:hyperparam_dt_max_depth} depicts results for varying levels of \textit {max\_depth}, averaged over \textit {max\_features}, wheres the opposite is done in \ref {fig:hyperparam_dt_max_depth}.\relax }{figure.caption.1}{}}
\newlabel{fig:hyperparam_logreg}{{2a}{3}{Logistic Regression: \textit {C}\relax }{figure.caption.2}{}}
\newlabel{sub@fig:hyperparam_logreg}{{a}{3}{Logistic Regression: \textit {C}\relax }{figure.caption.2}{}}
\newlabel{fig:hyperparam_rf}{{2b}{3}{Random Forest: \textit {n\_estimators}\relax }{figure.caption.2}{}}
\newlabel{sub@fig:hyperparam_rf}{{b}{3}{Random Forest: \textit {n\_estimators}\relax }{figure.caption.2}{}}
\newlabel{fig:hyperparam_bagdt}{{2c}{3}{Bagged Decision Trees: \textit {n\_estimators}\relax }{figure.caption.2}{}}
\newlabel{sub@fig:hyperparam_bagdt}{{c}{3}{Bagged Decision Trees: \textit {n\_estimators}\relax }{figure.caption.2}{}}
\newlabel{fig:hyperparam_bstdt}{{2d}{3}{Boosted Decision Trees: \textit {n\_estimators}\relax }{figure.caption.2}{}}
\newlabel{sub@fig:hyperparam_bstdt}{{d}{3}{Boosted Decision Trees: \textit {n\_estimators}\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Validation score by hyperparameter value for Logistic Regression (\ref  {fig:hyperparam_logreg}), Random Forest (\ref  {fig:hyperparam_rf}), Bagged Decision Trees (\ref  {fig:hyperparam_bagdt}), and Boosted Decision Trees (\ref  {fig:hyperparam_bstdt}).\relax }}{3}{figure.caption.2}}
\newlabel{fig:hyperparam_others}{{2}{3}{Validation score by hyperparameter value for Logistic Regression (\ref {fig:hyperparam_logreg}), Random Forest (\ref {fig:hyperparam_rf}), Bagged Decision Trees (\ref {fig:hyperparam_bagdt}), and Boosted Decision Trees (\ref {fig:hyperparam_bstdt}).\relax }{figure.caption.2}{}}
\newlabel{fig:perf_by_trainsplit_tr}{{3a}{4}{Training accuracy\relax }{figure.caption.3}{}}
\newlabel{sub@fig:perf_by_trainsplit_tr}{{a}{4}{Training accuracy\relax }{figure.caption.3}{}}
\newlabel{fig:perf_by_trainsplit_te}{{3b}{4}{Testing accuracy\relax }{figure.caption.3}{}}
\newlabel{sub@fig:perf_by_trainsplit_te}{{b}{4}{Testing accuracy\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Training (\ref  {fig:perf_by_trainsplit_tr}) and testing (\ref  {fig:perf_by_trainsplit_te}) accuracy by train split and classifier, averaged over problems and shuffles (rf: Random Forest, logreg: Logistic Regression, dt: Decision Tree, bagdt: Bagged Trees, bstdt: Boosted Trees)\relax }}{4}{figure.caption.3}}
\newlabel{fig:perf_by_trainsplit}{{3}{4}{Training (\ref {fig:perf_by_trainsplit_tr}) and testing (\ref {fig:perf_by_trainsplit_te}) accuracy by train split and classifier, averaged over problems and shuffles (rf: Random Forest, logreg: Logistic Regression, dt: Decision Tree, bagdt: Bagged Trees, bstdt: Boosted Trees)\relax }{figure.caption.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Best hyperparameter values after grid search by classifier and problem in each of three random shuffles (0.8 train split):\relax }}{4}{table.caption.4}}
\newlabel{tab:best_hyperparams_by_problem_shuffles}{{1}{4}{Best hyperparameter values after grid search by classifier and problem in each of three random shuffles (0.8 train split):\relax }{table.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Classifier testing accuracy by problem, averaged over shuffles (0.8 train split):\relax }}{5}{table.caption.5}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Ranked classifiers by testing accuracy, averaged over problems and shuffles (0.8 train split):\relax }}{5}{table.caption.6}}
\newlabel{tab:clf_ranking}{{3}{5}{Ranked classifiers by testing accuracy, averaged over problems and shuffles (0.8 train split):\relax }{table.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Conclusion}{5}{section.4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Bonus Points}{5}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}References}{5}{section.6}}
\bibdata{sample}
\newlabel{app:theorem}{{6}{6}{Appendix A}{section*.7}{}}
